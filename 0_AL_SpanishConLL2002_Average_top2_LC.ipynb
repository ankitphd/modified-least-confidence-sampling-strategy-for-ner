{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "import sklearn                                                              # scikit-learn learn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "            \n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Users\\\\ADMIN\\\\Desktop\\\\My Code\\\\Try NER\\\\NER Dataset\\\\final conll 2002 dataset\\\\espanish\\\\esp_train_pos_set.pkl\", 'rb') as fp:        # unpickling       notice    r   for read\n",
    "    train_sents = pickle.load(fp)\n",
    "    \n",
    "with open(\"C:\\\\Users\\\\ADMIN\\\\Desktop\\\\My Code\\\\Try NER\\\\NER Dataset\\\\final conll 2002 dataset\\\\espanish\\\\esp_testa_pos_set.pkl\", 'rb') as fp:        # unpickling       notice    r   for read\n",
    "    testa_sents = pickle.load(fp)\n",
    "    \n",
    "with open(\"C:\\\\Users\\\\ADMIN\\\\Desktop\\\\My Code\\\\Try NER\\\\NER Dataset\\\\final conll 2002 dataset\\\\espanish\\\\esp_testb_pos_set.pkl\", 'rb') as fp:        # unpickling       notice    r   for read\n",
    "    testb_sents = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Melbourne', 'NP', 'B-LOC'), ('(', 'Fpa', 'O'), ('Australia', 'NP', 'B-LOC'), (')', 'Fpt', 'O'), (',', 'Fc', 'O'), ('25', 'Z', 'O'), ('may', 'NC', 'O'), ('(', 'Fpa', 'O'), ('EFE', 'NC', 'B-ORG'), (')', 'Fpt', 'O'), ('.', 'Fp', 'O')]\n",
      "\n",
      " [('Sao', 'NC', 'B-LOC'), ('Paulo', 'VMI', 'I-LOC'), ('(', 'Fpa', 'O'), ('Brasil', 'NC', 'B-LOC'), (')', 'Fpt', 'O'), (',', 'Fc', 'O'), ('23', 'Z', 'O'), ('may', 'NC', 'O'), ('(', 'Fpa', 'O'), ('EFECOM', 'NP', 'B-ORG'), (')', 'Fpt', 'O'), ('.', 'Fp', 'O')]\n",
      "\n",
      " [('La', 'DA', 'B-LOC'), ('Coruña', 'NC', 'I-LOC'), (',', 'Fc', 'O'), ('23', 'Z', 'O'), ('may', 'NC', 'O'), ('(', 'Fpa', 'O'), ('EFECOM', 'NP', 'B-ORG'), (')', 'Fpt', 'O'), ('.', 'Fp', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print(train_sents[0])\n",
    "\n",
    "print(\"\\n\", testa_sents[0] )\n",
    "\n",
    "print(\"\\n\", testb_sents[0] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_type(word):\n",
    "    if word.isdigit(): \n",
    "        return \"Digit\"\n",
    "    elif word.isalpha():\n",
    "        return \"Alpha\"\n",
    "    elif word.isalnum():\n",
    "        return \"Alnum\"\n",
    "    else:\n",
    "        return \"None\"\n",
    "\n",
    "def get_word_case(word):\n",
    "    if word.istitle():\n",
    "        return \"Title\"\n",
    "    elif word.isupper():\n",
    "        return \"Upper\"\n",
    "    elif word.islower(): \n",
    "        return \"Lower\"\n",
    "    else:\n",
    "        return \"None\"\n",
    "    \n",
    "def get_pattern(token):\n",
    "    r = ''\n",
    "    for c in token:\n",
    "        if c.isupper():\n",
    "            r += 'U'\n",
    "        elif c.islower():\n",
    "            r += 'L'\n",
    "        elif c.isdigit():\n",
    "            r += 'D'\n",
    "        elif c in ('.', ','):\n",
    "            r += '.'\n",
    "        elif c in (';', ':', '?', '!'):\n",
    "            r += ';'\n",
    "        elif c in ('+', '*', '/', '=', '|', '_', '#'):\n",
    "            r += '#'\n",
    "        elif c in ('-'):\n",
    "            r += '-'\n",
    "        elif c in ('(', '{', '[', '<'):\n",
    "            r += '('\n",
    "        elif c in (')', '}', ']', '>'):\n",
    "            r += ')'\n",
    "        else:\n",
    "            r += c\n",
    "    return r    \n",
    "\n",
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word.len()': len(word),\n",
    "        'word[-4:]': word[-4:],\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word[:2]': word[:2],\n",
    "        'word[:3]': word[:3],\n",
    "        'word[:4]': word[:4],\n",
    "        'word.type': get_word_type(word),\n",
    "        'word.case()': get_word_case(word),\n",
    "        'word.pattern()': get_pattern(word),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2]        \n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.len()': len(word1),\n",
    "            '-1:word.type': get_word_type(word1),\n",
    "            '-1:word.case()': get_word_case(word1),\n",
    "            '-1:word.pattern()': get_pattern(word1),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2]\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.len()': len(word1),\n",
    "            '+1:word.type': get_word_type(word1),\n",
    "            '+1:word.case()': get_word_case(word1),\n",
    "            '+1:word.pattern()': get_pattern(word1),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2]\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "        \n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias': 1.0,\n",
       " 'word.lower()': 'australia',\n",
       " 'word.len()': 9,\n",
       " 'word[-4:]': 'alia',\n",
       " 'word[-3:]': 'lia',\n",
       " 'word[-2:]': 'ia',\n",
       " 'word[:2]': 'Au',\n",
       " 'word[:3]': 'Aus',\n",
       " 'word[:4]': 'Aust',\n",
       " 'word.type': 'Alpha',\n",
       " 'word.case()': 'Title',\n",
       " 'word.pattern()': 'ULLLLLLLL',\n",
       " 'postag': 'NP',\n",
       " 'postag[:2]': 'NP',\n",
       " '-1:word.lower()': '(',\n",
       " '-1:word.len()': 1,\n",
       " '-1:word.type': 'None',\n",
       " '-1:word.case()': 'None',\n",
       " '-1:word.pattern()': '(',\n",
       " '-1:postag': 'Fpa',\n",
       " '-1:postag[:2]': 'Fp',\n",
       " '+1:word.lower()': ')',\n",
       " '+1:word.len()': 1,\n",
       " '+1:word.type': 'None',\n",
       " '+1:word.case()': 'None',\n",
       " '+1:word.pattern()': ')',\n",
       " '+1:postag': 'Fpt',\n",
       " '+1:postag[:2]': 'Fp'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(train_sents[0])[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'bias': 1.0, 'word.lower()': 'melbourne', 'word.len()': 9, 'word[-4:]': 'urne', 'word[-3:]': 'rne', 'word[-2:]': 'ne', 'word[:2]': 'Me', 'word[:3]': 'Mel', 'word[:4]': 'Melb', 'word.type': 'Alpha', 'word.case()': 'Title', 'word.pattern()': 'ULLLLLLLL', 'postag': 'NP', 'postag[:2]': 'NP', 'BOS': True, '+1:word.lower()': '(', '+1:word.len()': 1, '+1:word.type': 'None', '+1:word.case()': 'None', '+1:word.pattern()': '(', '+1:postag': 'Fpa', '+1:postag[:2]': 'Fp'}, {'bias': 1.0, 'word.lower()': '(', 'word.len()': 1, 'word[-4:]': '(', 'word[-3:]': '(', 'word[-2:]': '(', 'word[:2]': '(', 'word[:3]': '(', 'word[:4]': '(', 'word.type': 'None', 'word.case()': 'None', 'word.pattern()': '(', 'postag': 'Fpa', 'postag[:2]': 'Fp', '-1:word.lower()': 'melbourne', '-1:word.len()': 9, '-1:word.type': 'Alpha', '-1:word.case()': 'Title', '-1:word.pattern()': 'ULLLLLLLL', '-1:postag': 'NP', '-1:postag[:2]': 'NP', '+1:word.lower()': 'australia', '+1:word.len()': 9, '+1:word.type': 'Alpha', '+1:word.case()': 'Title', '+1:word.pattern()': 'ULLLLLLLL', '+1:postag': 'NP', '+1:postag[:2]': 'NP'}, {'bias': 1.0, 'word.lower()': 'australia', 'word.len()': 9, 'word[-4:]': 'alia', 'word[-3:]': 'lia', 'word[-2:]': 'ia', 'word[:2]': 'Au', 'word[:3]': 'Aus', 'word[:4]': 'Aust', 'word.type': 'Alpha', 'word.case()': 'Title', 'word.pattern()': 'ULLLLLLLL', 'postag': 'NP', 'postag[:2]': 'NP', '-1:word.lower()': '(', '-1:word.len()': 1, '-1:word.type': 'None', '-1:word.case()': 'None', '-1:word.pattern()': '(', '-1:postag': 'Fpa', '-1:postag[:2]': 'Fp', '+1:word.lower()': ')', '+1:word.len()': 1, '+1:word.type': 'None', '+1:word.case()': 'None', '+1:word.pattern()': ')', '+1:postag': 'Fpt', '+1:postag[:2]': 'Fp'}, {'bias': 1.0, 'word.lower()': ')', 'word.len()': 1, 'word[-4:]': ')', 'word[-3:]': ')', 'word[-2:]': ')', 'word[:2]': ')', 'word[:3]': ')', 'word[:4]': ')', 'word.type': 'None', 'word.case()': 'None', 'word.pattern()': ')', 'postag': 'Fpt', 'postag[:2]': 'Fp', '-1:word.lower()': 'australia', '-1:word.len()': 9, '-1:word.type': 'Alpha', '-1:word.case()': 'Title', '-1:word.pattern()': 'ULLLLLLLL', '-1:postag': 'NP', '-1:postag[:2]': 'NP', '+1:word.lower()': ',', '+1:word.len()': 1, '+1:word.type': 'None', '+1:word.case()': 'None', '+1:word.pattern()': '.', '+1:postag': 'Fc', '+1:postag[:2]': 'Fc'}, {'bias': 1.0, 'word.lower()': ',', 'word.len()': 1, 'word[-4:]': ',', 'word[-3:]': ',', 'word[-2:]': ',', 'word[:2]': ',', 'word[:3]': ',', 'word[:4]': ',', 'word.type': 'None', 'word.case()': 'None', 'word.pattern()': '.', 'postag': 'Fc', 'postag[:2]': 'Fc', '-1:word.lower()': ')', '-1:word.len()': 1, '-1:word.type': 'None', '-1:word.case()': 'None', '-1:word.pattern()': ')', '-1:postag': 'Fpt', '-1:postag[:2]': 'Fp', '+1:word.lower()': '25', '+1:word.len()': 2, '+1:word.type': 'Digit', '+1:word.case()': 'None', '+1:word.pattern()': 'DD', '+1:postag': 'Z', '+1:postag[:2]': 'Z'}, {'bias': 1.0, 'word.lower()': '25', 'word.len()': 2, 'word[-4:]': '25', 'word[-3:]': '25', 'word[-2:]': '25', 'word[:2]': '25', 'word[:3]': '25', 'word[:4]': '25', 'word.type': 'Digit', 'word.case()': 'None', 'word.pattern()': 'DD', 'postag': 'Z', 'postag[:2]': 'Z', '-1:word.lower()': ',', '-1:word.len()': 1, '-1:word.type': 'None', '-1:word.case()': 'None', '-1:word.pattern()': '.', '-1:postag': 'Fc', '-1:postag[:2]': 'Fc', '+1:word.lower()': 'may', '+1:word.len()': 3, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LLL', '+1:postag': 'NC', '+1:postag[:2]': 'NC'}, {'bias': 1.0, 'word.lower()': 'may', 'word.len()': 3, 'word[-4:]': 'may', 'word[-3:]': 'may', 'word[-2:]': 'ay', 'word[:2]': 'ma', 'word[:3]': 'may', 'word[:4]': 'may', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LLL', 'postag': 'NC', 'postag[:2]': 'NC', '-1:word.lower()': '25', '-1:word.len()': 2, '-1:word.type': 'Digit', '-1:word.case()': 'None', '-1:word.pattern()': 'DD', '-1:postag': 'Z', '-1:postag[:2]': 'Z', '+1:word.lower()': '(', '+1:word.len()': 1, '+1:word.type': 'None', '+1:word.case()': 'None', '+1:word.pattern()': '(', '+1:postag': 'Fpa', '+1:postag[:2]': 'Fp'}, {'bias': 1.0, 'word.lower()': '(', 'word.len()': 1, 'word[-4:]': '(', 'word[-3:]': '(', 'word[-2:]': '(', 'word[:2]': '(', 'word[:3]': '(', 'word[:4]': '(', 'word.type': 'None', 'word.case()': 'None', 'word.pattern()': '(', 'postag': 'Fpa', 'postag[:2]': 'Fp', '-1:word.lower()': 'may', '-1:word.len()': 3, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LLL', '-1:postag': 'NC', '-1:postag[:2]': 'NC', '+1:word.lower()': 'efe', '+1:word.len()': 3, '+1:word.type': 'Alpha', '+1:word.case()': 'Upper', '+1:word.pattern()': 'UUU', '+1:postag': 'NC', '+1:postag[:2]': 'NC'}, {'bias': 1.0, 'word.lower()': 'efe', 'word.len()': 3, 'word[-4:]': 'EFE', 'word[-3:]': 'EFE', 'word[-2:]': 'FE', 'word[:2]': 'EF', 'word[:3]': 'EFE', 'word[:4]': 'EFE', 'word.type': 'Alpha', 'word.case()': 'Upper', 'word.pattern()': 'UUU', 'postag': 'NC', 'postag[:2]': 'NC', '-1:word.lower()': '(', '-1:word.len()': 1, '-1:word.type': 'None', '-1:word.case()': 'None', '-1:word.pattern()': '(', '-1:postag': 'Fpa', '-1:postag[:2]': 'Fp', '+1:word.lower()': ')', '+1:word.len()': 1, '+1:word.type': 'None', '+1:word.case()': 'None', '+1:word.pattern()': ')', '+1:postag': 'Fpt', '+1:postag[:2]': 'Fp'}, {'bias': 1.0, 'word.lower()': ')', 'word.len()': 1, 'word[-4:]': ')', 'word[-3:]': ')', 'word[-2:]': ')', 'word[:2]': ')', 'word[:3]': ')', 'word[:4]': ')', 'word.type': 'None', 'word.case()': 'None', 'word.pattern()': ')', 'postag': 'Fpt', 'postag[:2]': 'Fp', '-1:word.lower()': 'efe', '-1:word.len()': 3, '-1:word.type': 'Alpha', '-1:word.case()': 'Upper', '-1:word.pattern()': 'UUU', '-1:postag': 'NC', '-1:postag[:2]': 'NC', '+1:word.lower()': '.', '+1:word.len()': 1, '+1:word.type': 'None', '+1:word.case()': 'None', '+1:word.pattern()': '.', '+1:postag': 'Fp', '+1:postag[:2]': 'Fp'}, {'bias': 1.0, 'word.lower()': '.', 'word.len()': 1, 'word[-4:]': '.', 'word[-3:]': '.', 'word[-2:]': '.', 'word[:2]': '.', 'word[:3]': '.', 'word[:4]': '.', 'word.type': 'None', 'word.case()': 'None', 'word.pattern()': '.', 'postag': 'Fp', 'postag[:2]': 'Fp', '-1:word.lower()': ')', '-1:word.len()': 1, '-1:word.type': 'None', '-1:word.case()': 'None', '-1:word.pattern()': ')', '-1:postag': 'Fpt', '-1:postag[:2]': 'Fp', 'EOS': True}]\n",
      "\n",
      "\n",
      "\n",
      "[{'bias': 1.0, 'word.lower()': '-', 'word.len()': 1, 'word[-4:]': '-', 'word[-3:]': '-', 'word[-2:]': '-', 'word[:2]': '-', 'word[:3]': '-', 'word[:4]': '-', 'word.type': 'None', 'word.case()': 'None', 'word.pattern()': '-', 'postag': 'Fg', 'postag[:2]': 'Fg', 'BOS': True, 'EOS': True}]\n",
      "\n",
      "\n",
      "\n",
      "[{'bias': 1.0, 'word.lower()': 'el', 'word.len()': 2, 'word[-4:]': 'El', 'word[-3:]': 'El', 'word[-2:]': 'El', 'word[:2]': 'El', 'word[:3]': 'El', 'word[:4]': 'El', 'word.type': 'Alpha', 'word.case()': 'Title', 'word.pattern()': 'UL', 'postag': 'DA', 'postag[:2]': 'DA', 'BOS': True, '+1:word.lower()': 'abogado', '+1:word.len()': 7, '+1:word.type': 'Alpha', '+1:word.case()': 'Title', '+1:word.pattern()': 'ULLLLLL', '+1:postag': 'NC', '+1:postag[:2]': 'NC'}, {'bias': 1.0, 'word.lower()': 'abogado', 'word.len()': 7, 'word[-4:]': 'gado', 'word[-3:]': 'ado', 'word[-2:]': 'do', 'word[:2]': 'Ab', 'word[:3]': 'Abo', 'word[:4]': 'Abog', 'word.type': 'Alpha', 'word.case()': 'Title', 'word.pattern()': 'ULLLLLL', 'postag': 'NC', 'postag[:2]': 'NC', '-1:word.lower()': 'el', '-1:word.len()': 2, '-1:word.type': 'Alpha', '-1:word.case()': 'Title', '-1:word.pattern()': 'UL', '-1:postag': 'DA', '-1:postag[:2]': 'DA', '+1:word.lower()': 'general', '+1:word.len()': 7, '+1:word.type': 'Alpha', '+1:word.case()': 'Title', '+1:word.pattern()': 'ULLLLLL', '+1:postag': 'AQ', '+1:postag[:2]': 'AQ'}, {'bias': 1.0, 'word.lower()': 'general', 'word.len()': 7, 'word[-4:]': 'eral', 'word[-3:]': 'ral', 'word[-2:]': 'al', 'word[:2]': 'Ge', 'word[:3]': 'Gen', 'word[:4]': 'Gene', 'word.type': 'Alpha', 'word.case()': 'Title', 'word.pattern()': 'ULLLLLL', 'postag': 'AQ', 'postag[:2]': 'AQ', '-1:word.lower()': 'abogado', '-1:word.len()': 7, '-1:word.type': 'Alpha', '-1:word.case()': 'Title', '-1:word.pattern()': 'ULLLLLL', '-1:postag': 'NC', '-1:postag[:2]': 'NC', '+1:word.lower()': 'del', '+1:word.len()': 3, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LLL', '+1:postag': 'SP', '+1:postag[:2]': 'SP'}, {'bias': 1.0, 'word.lower()': 'del', 'word.len()': 3, 'word[-4:]': 'del', 'word[-3:]': 'del', 'word[-2:]': 'el', 'word[:2]': 'de', 'word[:3]': 'del', 'word[:4]': 'del', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LLL', 'postag': 'SP', 'postag[:2]': 'SP', '-1:word.lower()': 'general', '-1:word.len()': 7, '-1:word.type': 'Alpha', '-1:word.case()': 'Title', '-1:word.pattern()': 'ULLLLLL', '-1:postag': 'AQ', '-1:postag[:2]': 'AQ', '+1:word.lower()': 'estado', '+1:word.len()': 6, '+1:word.type': 'Alpha', '+1:word.case()': 'Title', '+1:word.pattern()': 'ULLLLL', '+1:postag': 'NC', '+1:postag[:2]': 'NC'}, {'bias': 1.0, 'word.lower()': 'estado', 'word.len()': 6, 'word[-4:]': 'tado', 'word[-3:]': 'ado', 'word[-2:]': 'do', 'word[:2]': 'Es', 'word[:3]': 'Est', 'word[:4]': 'Esta', 'word.type': 'Alpha', 'word.case()': 'Title', 'word.pattern()': 'ULLLLL', 'postag': 'NC', 'postag[:2]': 'NC', '-1:word.lower()': 'del', '-1:word.len()': 3, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LLL', '-1:postag': 'SP', '-1:postag[:2]': 'SP', '+1:word.lower()': ',', '+1:word.len()': 1, '+1:word.type': 'None', '+1:word.case()': 'None', '+1:word.pattern()': '.', '+1:postag': 'Fc', '+1:postag[:2]': 'Fc'}, {'bias': 1.0, 'word.lower()': ',', 'word.len()': 1, 'word[-4:]': ',', 'word[-3:]': ',', 'word[-2:]': ',', 'word[:2]': ',', 'word[:3]': ',', 'word[:4]': ',', 'word.type': 'None', 'word.case()': 'None', 'word.pattern()': '.', 'postag': 'Fc', 'postag[:2]': 'Fc', '-1:word.lower()': 'estado', '-1:word.len()': 6, '-1:word.type': 'Alpha', '-1:word.case()': 'Title', '-1:word.pattern()': 'ULLLLL', '-1:postag': 'NC', '-1:postag[:2]': 'NC', '+1:word.lower()': 'daryl', '+1:word.len()': 5, '+1:word.type': 'Alpha', '+1:word.case()': 'Title', '+1:word.pattern()': 'ULLLL', '+1:postag': 'VMI', '+1:postag[:2]': 'VM'}, {'bias': 1.0, 'word.lower()': 'daryl', 'word.len()': 5, 'word[-4:]': 'aryl', 'word[-3:]': 'ryl', 'word[-2:]': 'yl', 'word[:2]': 'Da', 'word[:3]': 'Dar', 'word[:4]': 'Dary', 'word.type': 'Alpha', 'word.case()': 'Title', 'word.pattern()': 'ULLLL', 'postag': 'VMI', 'postag[:2]': 'VM', '-1:word.lower()': ',', '-1:word.len()': 1, '-1:word.type': 'None', '-1:word.case()': 'None', '-1:word.pattern()': '.', '-1:postag': 'Fc', '-1:postag[:2]': 'Fc', '+1:word.lower()': 'williams', '+1:word.len()': 8, '+1:word.type': 'Alpha', '+1:word.case()': 'Title', '+1:word.pattern()': 'ULLLLLLL', '+1:postag': 'NC', '+1:postag[:2]': 'NC'}, {'bias': 1.0, 'word.lower()': 'williams', 'word.len()': 8, 'word[-4:]': 'iams', 'word[-3:]': 'ams', 'word[-2:]': 'ms', 'word[:2]': 'Wi', 'word[:3]': 'Wil', 'word[:4]': 'Will', 'word.type': 'Alpha', 'word.case()': 'Title', 'word.pattern()': 'ULLLLLLL', 'postag': 'NC', 'postag[:2]': 'NC', '-1:word.lower()': 'daryl', '-1:word.len()': 5, '-1:word.type': 'Alpha', '-1:word.case()': 'Title', '-1:word.pattern()': 'ULLLL', '-1:postag': 'VMI', '-1:postag[:2]': 'VM', '+1:word.lower()': ',', '+1:word.len()': 1, '+1:word.type': 'None', '+1:word.case()': 'None', '+1:word.pattern()': '.', '+1:postag': 'Fc', '+1:postag[:2]': 'Fc'}, {'bias': 1.0, 'word.lower()': ',', 'word.len()': 1, 'word[-4:]': ',', 'word[-3:]': ',', 'word[-2:]': ',', 'word[:2]': ',', 'word[:3]': ',', 'word[:4]': ',', 'word.type': 'None', 'word.case()': 'None', 'word.pattern()': '.', 'postag': 'Fc', 'postag[:2]': 'Fc', '-1:word.lower()': 'williams', '-1:word.len()': 8, '-1:word.type': 'Alpha', '-1:word.case()': 'Title', '-1:word.pattern()': 'ULLLLLLL', '-1:postag': 'NC', '-1:postag[:2]': 'NC', '+1:word.lower()': 'subrayó', '+1:word.len()': 7, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LLLLLLL', '+1:postag': 'VMI', '+1:postag[:2]': 'VM'}, {'bias': 1.0, 'word.lower()': 'subrayó', 'word.len()': 7, 'word[-4:]': 'rayó', 'word[-3:]': 'ayó', 'word[-2:]': 'yó', 'word[:2]': 'su', 'word[:3]': 'sub', 'word[:4]': 'subr', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LLLLLLL', 'postag': 'VMI', 'postag[:2]': 'VM', '-1:word.lower()': ',', '-1:word.len()': 1, '-1:word.type': 'None', '-1:word.case()': 'None', '-1:word.pattern()': '.', '-1:postag': 'Fc', '-1:postag[:2]': 'Fc', '+1:word.lower()': 'hoy', '+1:word.len()': 3, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LLL', '+1:postag': 'RG', '+1:postag[:2]': 'RG'}, {'bias': 1.0, 'word.lower()': 'hoy', 'word.len()': 3, 'word[-4:]': 'hoy', 'word[-3:]': 'hoy', 'word[-2:]': 'oy', 'word[:2]': 'ho', 'word[:3]': 'hoy', 'word[:4]': 'hoy', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LLL', 'postag': 'RG', 'postag[:2]': 'RG', '-1:word.lower()': 'subrayó', '-1:word.len()': 7, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LLLLLLL', '-1:postag': 'VMI', '-1:postag[:2]': 'VM', '+1:word.lower()': 'la', '+1:word.len()': 2, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LL', '+1:postag': 'DA', '+1:postag[:2]': 'DA'}, {'bias': 1.0, 'word.lower()': 'la', 'word.len()': 2, 'word[-4:]': 'la', 'word[-3:]': 'la', 'word[-2:]': 'la', 'word[:2]': 'la', 'word[:3]': 'la', 'word[:4]': 'la', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LL', 'postag': 'DA', 'postag[:2]': 'DA', '-1:word.lower()': 'hoy', '-1:word.len()': 3, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LLL', '-1:postag': 'RG', '-1:postag[:2]': 'RG', '+1:word.lower()': 'necesidad', '+1:word.len()': 9, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LLLLLLLLL', '+1:postag': 'NC', '+1:postag[:2]': 'NC'}, {'bias': 1.0, 'word.lower()': 'necesidad', 'word.len()': 9, 'word[-4:]': 'idad', 'word[-3:]': 'dad', 'word[-2:]': 'ad', 'word[:2]': 'ne', 'word[:3]': 'nec', 'word[:4]': 'nece', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LLLLLLLLL', 'postag': 'NC', 'postag[:2]': 'NC', '-1:word.lower()': 'la', '-1:word.len()': 2, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LL', '-1:postag': 'DA', '-1:postag[:2]': 'DA', '+1:word.lower()': 'de', '+1:word.len()': 2, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LL', '+1:postag': 'SP', '+1:postag[:2]': 'SP'}, {'bias': 1.0, 'word.lower()': 'de', 'word.len()': 2, 'word[-4:]': 'de', 'word[-3:]': 'de', 'word[-2:]': 'de', 'word[:2]': 'de', 'word[:3]': 'de', 'word[:4]': 'de', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LL', 'postag': 'SP', 'postag[:2]': 'SP', '-1:word.lower()': 'necesidad', '-1:word.len()': 9, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LLLLLLLLL', '-1:postag': 'NC', '-1:postag[:2]': 'NC', '+1:word.lower()': 'tomar', '+1:word.len()': 5, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LLLLL', '+1:postag': 'VMN', '+1:postag[:2]': 'VM'}, {'bias': 1.0, 'word.lower()': 'tomar', 'word.len()': 5, 'word[-4:]': 'omar', 'word[-3:]': 'mar', 'word[-2:]': 'ar', 'word[:2]': 'to', 'word[:3]': 'tom', 'word[:4]': 'toma', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LLLLL', 'postag': 'VMN', 'postag[:2]': 'VM', '-1:word.lower()': 'de', '-1:word.len()': 2, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LL', '-1:postag': 'SP', '-1:postag[:2]': 'SP', '+1:word.lower()': 'medidas', '+1:word.len()': 7, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LLLLLLL', '+1:postag': 'NC', '+1:postag[:2]': 'NC'}, {'bias': 1.0, 'word.lower()': 'medidas', 'word.len()': 7, 'word[-4:]': 'idas', 'word[-3:]': 'das', 'word[-2:]': 'as', 'word[:2]': 'me', 'word[:3]': 'med', 'word[:4]': 'medi', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LLLLLLL', 'postag': 'NC', 'postag[:2]': 'NC', '-1:word.lower()': 'tomar', '-1:word.len()': 5, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LLLLL', '-1:postag': 'VMN', '-1:postag[:2]': 'VM', '+1:word.lower()': 'para', '+1:word.len()': 4, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LLLL', '+1:postag': 'SP', '+1:postag[:2]': 'SP'}, {'bias': 1.0, 'word.lower()': 'para', 'word.len()': 4, 'word[-4:]': 'para', 'word[-3:]': 'ara', 'word[-2:]': 'ra', 'word[:2]': 'pa', 'word[:3]': 'par', 'word[:4]': 'para', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LLLL', 'postag': 'SP', 'postag[:2]': 'SP', '-1:word.lower()': 'medidas', '-1:word.len()': 7, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LLLLLLL', '-1:postag': 'NC', '-1:postag[:2]': 'NC', '+1:word.lower()': 'proteger', '+1:word.len()': 8, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LLLLLLLL', '+1:postag': 'VMN', '+1:postag[:2]': 'VM'}, {'bias': 1.0, 'word.lower()': 'proteger', 'word.len()': 8, 'word[-4:]': 'eger', 'word[-3:]': 'ger', 'word[-2:]': 'er', 'word[:2]': 'pr', 'word[:3]': 'pro', 'word[:4]': 'prot', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LLLLLLLL', 'postag': 'VMN', 'postag[:2]': 'VM', '-1:word.lower()': 'para', '-1:word.len()': 4, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LLLL', '-1:postag': 'SP', '-1:postag[:2]': 'SP', '+1:word.lower()': 'al', '+1:word.len()': 2, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LL', '+1:postag': 'SP', '+1:postag[:2]': 'SP'}, {'bias': 1.0, 'word.lower()': 'al', 'word.len()': 2, 'word[-4:]': 'al', 'word[-3:]': 'al', 'word[-2:]': 'al', 'word[:2]': 'al', 'word[:3]': 'al', 'word[:4]': 'al', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LL', 'postag': 'SP', 'postag[:2]': 'SP', '-1:word.lower()': 'proteger', '-1:word.len()': 8, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LLLLLLLL', '-1:postag': 'VMN', '-1:postag[:2]': 'VM', '+1:word.lower()': 'sistema', '+1:word.len()': 7, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LLLLLLL', '+1:postag': 'NC', '+1:postag[:2]': 'NC'}, {'bias': 1.0, 'word.lower()': 'sistema', 'word.len()': 7, 'word[-4:]': 'tema', 'word[-3:]': 'ema', 'word[-2:]': 'ma', 'word[:2]': 'si', 'word[:3]': 'sis', 'word[:4]': 'sist', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LLLLLLL', 'postag': 'NC', 'postag[:2]': 'NC', '-1:word.lower()': 'al', '-1:word.len()': 2, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LL', '-1:postag': 'SP', '-1:postag[:2]': 'SP', '+1:word.lower()': 'judicial', '+1:word.len()': 8, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LLLLLLLL', '+1:postag': 'AQ', '+1:postag[:2]': 'AQ'}, {'bias': 1.0, 'word.lower()': 'judicial', 'word.len()': 8, 'word[-4:]': 'cial', 'word[-3:]': 'ial', 'word[-2:]': 'al', 'word[:2]': 'ju', 'word[:3]': 'jud', 'word[:4]': 'judi', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LLLLLLLL', 'postag': 'AQ', 'postag[:2]': 'AQ', '-1:word.lower()': 'sistema', '-1:word.len()': 7, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LLLLLLL', '-1:postag': 'NC', '-1:postag[:2]': 'NC', '+1:word.lower()': 'australiano', '+1:word.len()': 11, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LLLLLLLLLLL', '+1:postag': 'AQ', '+1:postag[:2]': 'AQ'}, {'bias': 1.0, 'word.lower()': 'australiano', 'word.len()': 11, 'word[-4:]': 'iano', 'word[-3:]': 'ano', 'word[-2:]': 'no', 'word[:2]': 'au', 'word[:3]': 'aus', 'word[:4]': 'aust', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LLLLLLLLLLL', 'postag': 'AQ', 'postag[:2]': 'AQ', '-1:word.lower()': 'judicial', '-1:word.len()': 8, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LLLLLLLL', '-1:postag': 'AQ', '-1:postag[:2]': 'AQ', '+1:word.lower()': 'frente', '+1:word.len()': 6, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LLLLLL', '+1:postag': 'RG', '+1:postag[:2]': 'RG'}, {'bias': 1.0, 'word.lower()': 'frente', 'word.len()': 6, 'word[-4:]': 'ente', 'word[-3:]': 'nte', 'word[-2:]': 'te', 'word[:2]': 'fr', 'word[:3]': 'fre', 'word[:4]': 'fren', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LLLLLL', 'postag': 'RG', 'postag[:2]': 'RG', '-1:word.lower()': 'australiano', '-1:word.len()': 11, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LLLLLLLLLLL', '-1:postag': 'AQ', '-1:postag[:2]': 'AQ', '+1:word.lower()': 'a', '+1:word.len()': 1, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'L', '+1:postag': 'SP', '+1:postag[:2]': 'SP'}, {'bias': 1.0, 'word.lower()': 'a', 'word.len()': 1, 'word[-4:]': 'a', 'word[-3:]': 'a', 'word[-2:]': 'a', 'word[:2]': 'a', 'word[:3]': 'a', 'word[:4]': 'a', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'L', 'postag': 'SP', 'postag[:2]': 'SP', '-1:word.lower()': 'frente', '-1:word.len()': 6, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LLLLLL', '-1:postag': 'RG', '-1:postag[:2]': 'RG', '+1:word.lower()': 'una', '+1:word.len()': 3, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LLL', '+1:postag': 'DI', '+1:postag[:2]': 'DI'}, {'bias': 1.0, 'word.lower()': 'una', 'word.len()': 3, 'word[-4:]': 'una', 'word[-3:]': 'una', 'word[-2:]': 'na', 'word[:2]': 'un', 'word[:3]': 'una', 'word[:4]': 'una', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LLL', 'postag': 'DI', 'postag[:2]': 'DI', '-1:word.lower()': 'a', '-1:word.len()': 1, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'L', '-1:postag': 'SP', '-1:postag[:2]': 'SP', '+1:word.lower()': 'página', '+1:word.len()': 6, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LLLLLL', '+1:postag': 'NC', '+1:postag[:2]': 'NC'}, {'bias': 1.0, 'word.lower()': 'página', 'word.len()': 6, 'word[-4:]': 'gina', 'word[-3:]': 'ina', 'word[-2:]': 'na', 'word[:2]': 'pá', 'word[:3]': 'pág', 'word[:4]': 'pági', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LLLLLL', 'postag': 'NC', 'postag[:2]': 'NC', '-1:word.lower()': 'una', '-1:word.len()': 3, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LLL', '-1:postag': 'DI', '-1:postag[:2]': 'DI', '+1:word.lower()': 'de', '+1:word.len()': 2, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LL', '+1:postag': 'SP', '+1:postag[:2]': 'SP'}, {'bias': 1.0, 'word.lower()': 'de', 'word.len()': 2, 'word[-4:]': 'de', 'word[-3:]': 'de', 'word[-2:]': 'de', 'word[:2]': 'de', 'word[:3]': 'de', 'word[:4]': 'de', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LL', 'postag': 'SP', 'postag[:2]': 'SP', '-1:word.lower()': 'página', '-1:word.len()': 6, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LLLLLL', '-1:postag': 'NC', '-1:postag[:2]': 'NC', '+1:word.lower()': 'internet', '+1:word.len()': 8, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LLLLLLLL', '+1:postag': 'NC', '+1:postag[:2]': 'NC'}, {'bias': 1.0, 'word.lower()': 'internet', 'word.len()': 8, 'word[-4:]': 'rnet', 'word[-3:]': 'net', 'word[-2:]': 'et', 'word[:2]': 'in', 'word[:3]': 'int', 'word[:4]': 'inte', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LLLLLLLL', 'postag': 'NC', 'postag[:2]': 'NC', '-1:word.lower()': 'de', '-1:word.len()': 2, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LL', '-1:postag': 'SP', '-1:postag[:2]': 'SP', '+1:word.lower()': 'que', '+1:word.len()': 3, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LLL', '+1:postag': 'PR', '+1:postag[:2]': 'PR'}, {'bias': 1.0, 'word.lower()': 'que', 'word.len()': 3, 'word[-4:]': 'que', 'word[-3:]': 'que', 'word[-2:]': 'ue', 'word[:2]': 'qu', 'word[:3]': 'que', 'word[:4]': 'que', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LLL', 'postag': 'PR', 'postag[:2]': 'PR', '-1:word.lower()': 'internet', '-1:word.len()': 8, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LLLLLLLL', '-1:postag': 'NC', '-1:postag[:2]': 'NC', '+1:word.lower()': 'imposibilita', '+1:word.len()': 12, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LLLLLLLLLLLL', '+1:postag': 'VMI', '+1:postag[:2]': 'VM'}, {'bias': 1.0, 'word.lower()': 'imposibilita', 'word.len()': 12, 'word[-4:]': 'lita', 'word[-3:]': 'ita', 'word[-2:]': 'ta', 'word[:2]': 'im', 'word[:3]': 'imp', 'word[:4]': 'impo', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LLLLLLLLLLLL', 'postag': 'VMI', 'postag[:2]': 'VM', '-1:word.lower()': 'que', '-1:word.len()': 3, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LLL', '-1:postag': 'PR', '-1:postag[:2]': 'PR', '+1:word.lower()': 'el', '+1:word.len()': 2, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LL', '+1:postag': 'DA', '+1:postag[:2]': 'DA'}, {'bias': 1.0, 'word.lower()': 'el', 'word.len()': 2, 'word[-4:]': 'el', 'word[-3:]': 'el', 'word[-2:]': 'el', 'word[:2]': 'el', 'word[:3]': 'el', 'word[:4]': 'el', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LL', 'postag': 'DA', 'postag[:2]': 'DA', '-1:word.lower()': 'imposibilita', '-1:word.len()': 12, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LLLLLLLLLLLL', '-1:postag': 'VMI', '-1:postag[:2]': 'VM', '+1:word.lower()': 'cumplimiento', '+1:word.len()': 12, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LLLLLLLLLLLL', '+1:postag': 'NC', '+1:postag[:2]': 'NC'}, {'bias': 1.0, 'word.lower()': 'cumplimiento', 'word.len()': 12, 'word[-4:]': 'ento', 'word[-3:]': 'nto', 'word[-2:]': 'to', 'word[:2]': 'cu', 'word[:3]': 'cum', 'word[:4]': 'cump', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LLLLLLLLLLLL', 'postag': 'NC', 'postag[:2]': 'NC', '-1:word.lower()': 'el', '-1:word.len()': 2, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LL', '-1:postag': 'DA', '-1:postag[:2]': 'DA', '+1:word.lower()': 'de', '+1:word.len()': 2, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LL', '+1:postag': 'SP', '+1:postag[:2]': 'SP'}, {'bias': 1.0, 'word.lower()': 'de', 'word.len()': 2, 'word[-4:]': 'de', 'word[-3:]': 'de', 'word[-2:]': 'de', 'word[:2]': 'de', 'word[:3]': 'de', 'word[:4]': 'de', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LL', 'postag': 'SP', 'postag[:2]': 'SP', '-1:word.lower()': 'cumplimiento', '-1:word.len()': 12, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LLLLLLLLLLLL', '-1:postag': 'NC', '-1:postag[:2]': 'NC', '+1:word.lower()': 'los', '+1:word.len()': 3, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LLL', '+1:postag': 'DA', '+1:postag[:2]': 'DA'}, {'bias': 1.0, 'word.lower()': 'los', 'word.len()': 3, 'word[-4:]': 'los', 'word[-3:]': 'los', 'word[-2:]': 'os', 'word[:2]': 'lo', 'word[:3]': 'los', 'word[:4]': 'los', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LLL', 'postag': 'DA', 'postag[:2]': 'DA', '-1:word.lower()': 'de', '-1:word.len()': 2, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LL', '-1:postag': 'SP', '-1:postag[:2]': 'SP', '+1:word.lower()': 'principios', '+1:word.len()': 10, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LLLLLLLLLL', '+1:postag': 'NC', '+1:postag[:2]': 'NC'}, {'bias': 1.0, 'word.lower()': 'principios', 'word.len()': 10, 'word[-4:]': 'pios', 'word[-3:]': 'ios', 'word[-2:]': 'os', 'word[:2]': 'pr', 'word[:3]': 'pri', 'word[:4]': 'prin', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LLLLLLLLLL', 'postag': 'NC', 'postag[:2]': 'NC', '-1:word.lower()': 'los', '-1:word.len()': 3, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LLL', '-1:postag': 'DA', '-1:postag[:2]': 'DA', '+1:word.lower()': 'básicos', '+1:word.len()': 7, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LLLLLLL', '+1:postag': 'AQ', '+1:postag[:2]': 'AQ'}, {'bias': 1.0, 'word.lower()': 'básicos', 'word.len()': 7, 'word[-4:]': 'icos', 'word[-3:]': 'cos', 'word[-2:]': 'os', 'word[:2]': 'bá', 'word[:3]': 'bás', 'word[:4]': 'bási', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LLLLLLL', 'postag': 'AQ', 'postag[:2]': 'AQ', '-1:word.lower()': 'principios', '-1:word.len()': 10, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LLLLLLLLLL', '-1:postag': 'NC', '-1:postag[:2]': 'NC', '+1:word.lower()': 'de', '+1:word.len()': 2, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LL', '+1:postag': 'SP', '+1:postag[:2]': 'SP'}, {'bias': 1.0, 'word.lower()': 'de', 'word.len()': 2, 'word[-4:]': 'de', 'word[-3:]': 'de', 'word[-2:]': 'de', 'word[:2]': 'de', 'word[:3]': 'de', 'word[:4]': 'de', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LL', 'postag': 'SP', 'postag[:2]': 'SP', '-1:word.lower()': 'básicos', '-1:word.len()': 7, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LLLLLLL', '-1:postag': 'AQ', '-1:postag[:2]': 'AQ', '+1:word.lower()': 'la', '+1:word.len()': 2, '+1:word.type': 'Alpha', '+1:word.case()': 'Lower', '+1:word.pattern()': 'LL', '+1:postag': 'DA', '+1:postag[:2]': 'DA'}, {'bias': 1.0, 'word.lower()': 'la', 'word.len()': 2, 'word[-4:]': 'la', 'word[-3:]': 'la', 'word[-2:]': 'la', 'word[:2]': 'la', 'word[:3]': 'la', 'word[:4]': 'la', 'word.type': 'Alpha', 'word.case()': 'Lower', 'word.pattern()': 'LL', 'postag': 'DA', 'postag[:2]': 'DA', '-1:word.lower()': 'de', '-1:word.len()': 2, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LL', '-1:postag': 'SP', '-1:postag[:2]': 'SP', '+1:word.lower()': 'ley', '+1:word.len()': 3, '+1:word.type': 'Alpha', '+1:word.case()': 'Title', '+1:word.pattern()': 'ULL', '+1:postag': 'NC', '+1:postag[:2]': 'NC'}, {'bias': 1.0, 'word.lower()': 'ley', 'word.len()': 3, 'word[-4:]': 'Ley', 'word[-3:]': 'Ley', 'word[-2:]': 'ey', 'word[:2]': 'Le', 'word[:3]': 'Ley', 'word[:4]': 'Ley', 'word.type': 'Alpha', 'word.case()': 'Title', 'word.pattern()': 'ULL', 'postag': 'NC', 'postag[:2]': 'NC', '-1:word.lower()': 'la', '-1:word.len()': 2, '-1:word.type': 'Alpha', '-1:word.case()': 'Lower', '-1:word.pattern()': 'LL', '-1:postag': 'DA', '-1:postag[:2]': 'DA', '+1:word.lower()': '.', '+1:word.len()': 1, '+1:word.type': 'None', '+1:word.case()': 'None', '+1:word.pattern()': '.', '+1:postag': 'Fp', '+1:postag[:2]': 'Fp'}, {'bias': 1.0, 'word.lower()': '.', 'word.len()': 1, 'word[-4:]': '.', 'word[-3:]': '.', 'word[-2:]': '.', 'word[:2]': '.', 'word[:3]': '.', 'word[:4]': '.', 'word.type': 'None', 'word.case()': 'None', 'word.pattern()': '.', 'postag': 'Fp', 'postag[:2]': 'Fp', '-1:word.lower()': 'ley', '-1:word.len()': 3, '-1:word.type': 'Alpha', '-1:word.case()': 'Title', '-1:word.pattern()': 'ULL', '-1:postag': 'NC', '-1:postag[:2]': 'NC', 'EOS': True}]\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "X_train = [sent2features(s) for s in train_sents]                        # 8323 sentence\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_testa = [sent2features(s) for s in testa_sents]                        # 1915 sentence\n",
    "y_testa = [sent2labels(s) for s in testa_sents]\n",
    "\n",
    "X_testb = [sent2features(s) for s in testb_sents]                        # 1517 sentence\n",
    "y_testb = [sent2labels(s) for s in testb_sents]\n",
    "\n",
    "print (X_train[0])\n",
    "print(\"\\n\\n\")\n",
    "print (X_train[1])\n",
    "print(\"\\n\\n\")\n",
    "print (X_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8323\n"
     ]
    }
   ],
   "source": [
    "n_sent_train = len(X_train)\n",
    "print(n_sent_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting 1 % sentences as seed for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "n_seed = math.floor(int(n_sent_train)/100)\n",
    "print(n_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Set our RNG seed for reproducibility.\n",
    "RANDOM_STATE_SEED = 123\n",
    "np.random.seed(RANDOM_STATE_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n",
      "8240\n",
      "8240\n"
     ]
    }
   ],
   "source": [
    "# Isolate our examples for our labeled dataset.\n",
    "n_labeled_examples = n_sent_train\n",
    "\n",
    "training_indices = np.random.choice(n_labeled_examples, n_seed , replace=False)\n",
    "\n",
    "training_indices = list(set(training_indices))\n",
    "print(len(training_indices))                                            # print 1\n",
    "initial_X_train = [X_train[x] for x in training_indices]      \n",
    "initial_Y_train = [y_train[x] for x in training_indices]\n",
    "\n",
    "# Isolate the non-training examples we'll be querying.\n",
    "X_pool = np.delete(X_train, training_indices).tolist()\n",
    "y_pool = np.delete(y_train, training_indices).tolist()\n",
    "\n",
    "\n",
    "print(len(X_pool))                                                       # print 2\n",
    "print(len(y_pool))                                                       # print 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    keep_tempfiles=None, max_iterations=100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.1, \n",
    "    c2=0.1, \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True,                             # all_possible_states is one more option to check\n",
    "    verbose = False\n",
    ")\n",
    "crf.fit(initial_X_train, initial_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ORG', 'I-ORG', 'B-PER', 'I-PER', 'B-LOC', 'B-MISC', 'I-MISC', 'I-LOC']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5442214555635854\n"
     ]
    }
   ],
   "source": [
    "# for storing f1 score of testa and testb\n",
    "\n",
    "predict_f1_testa = []\n",
    "predict_f1_testb = []\n",
    "\n",
    "y_preda = crf.predict(X_testa)                                                  ##Iter 0\n",
    "\n",
    "predict_f1_testa.append(metrics.flat_f1_score(y_testa, y_preda, average='weighted', labels=labels))\n",
    "\n",
    "print(predict_f1_testa[-1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5523012708545431\n"
     ]
    }
   ],
   "source": [
    "y_predb = crf.predict(X_testb)\n",
    "predict_f1_testb.append(metrics.flat_f1_score(y_testb, y_predb, average='weighted', labels=labels))      # Return F1 score for sequence items.\n",
    "                                                              # check sklearn.metrics.f1_score parameters\n",
    "print(predict_f1_testb[-1])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py:71: FutureWarning: Pass labels=['B-LOC', 'I-LOC', 'B-MISC', 'I-MISC', 'B-ORG', 'I-ORG', 'B-PER', 'I-PER'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC      0.453     0.664     0.539       984\n",
      "       I-LOC      0.384     0.318     0.347       337\n",
      "      B-MISC      0.234     0.083     0.123       445\n",
      "      I-MISC      0.280     0.092     0.138       654\n",
      "       B-ORG      0.709     0.645     0.675      1700\n",
      "       I-ORG      0.642     0.610     0.626      1366\n",
      "       B-PER      0.639     0.520     0.574      1222\n",
      "       I-PER      0.683     0.771     0.724       859\n",
      "\n",
      "   micro avg      0.592     0.540     0.565      7567\n",
      "   macro avg      0.503     0.463     0.468      7567\n",
      "weighted avg      0.570     0.540     0.544      7567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# group B and I results\n",
    "sorted_labels = sorted(\n",
    "    labels, \n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_testa, y_preda, labels=sorted_labels, digits=3\n",
    ")) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC      0.553     0.613     0.581      1084\n",
      "       I-LOC      0.277     0.182     0.219       325\n",
      "      B-MISC      0.236     0.074     0.112       339\n",
      "      I-MISC      0.370     0.102     0.160       557\n",
      "       B-ORG      0.629     0.643     0.636      1400\n",
      "       I-ORG      0.616     0.624     0.620      1104\n",
      "       B-PER      0.680     0.698     0.689       735\n",
      "       I-PER      0.750     0.841     0.793       634\n",
      "\n",
      "   micro avg      0.605     0.557     0.580      6178\n",
      "   macro avg      0.514     0.472     0.476      6178\n",
      "weighted avg      0.568     0.557     0.552      6178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# group B and I results\n",
    "sorted_labels = sorted(\n",
    "    labels, \n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_testb, y_predb, labels=sorted_labels, digits=3\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING iteration 1 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  8230 \n",
      "\n",
      "\t # of sent in y_pool:  8230 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  93 \n",
      "\n",
      "\t # of sent in y_train:  93 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.5616581979519867 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  2 \n",
      "\n",
      "f1 Score for testb is :  0.5780292079006509 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  2 \n",
      "\n",
      "Task 5 completed of iteration 1....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 2 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  8220 \n",
      "\n",
      "\t # of sent in y_pool:  8220 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  103 \n",
      "\n",
      "\t # of sent in y_train:  103 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.5668748911696174 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  3 \n",
      "\n",
      "f1 Score for testb is :  0.5819454260827424 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  3 \n",
      "\n",
      "Task 5 completed of iteration 2....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 3 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  8210 \n",
      "\n",
      "\t # of sent in y_pool:  8210 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  113 \n",
      "\n",
      "\t # of sent in y_train:  113 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.5622918544369189 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  4 \n",
      "\n",
      "f1 Score for testb is :  0.5849115866821858 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  4 \n",
      "\n",
      "Task 5 completed of iteration 3....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 4 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  8200 \n",
      "\n",
      "\t # of sent in y_pool:  8200 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  123 \n",
      "\n",
      "\t # of sent in y_train:  123 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.575020471892929 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  5 \n",
      "\n",
      "f1 Score for testb is :  0.5897738581947952 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  5 \n",
      "\n",
      "Task 5 completed of iteration 4....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 5 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  8190 \n",
      "\n",
      "\t # of sent in y_pool:  8190 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  133 \n",
      "\n",
      "\t # of sent in y_train:  133 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.5704636678652358 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  6 \n",
      "\n",
      "f1 Score for testb is :  0.5928646079336878 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  6 \n",
      "\n",
      "Task 5 completed of iteration 5....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 6 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  8180 \n",
      "\n",
      "\t # of sent in y_pool:  8180 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  143 \n",
      "\n",
      "\t # of sent in y_train:  143 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.5691724867132371 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  7 \n",
      "\n",
      "f1 Score for testb is :  0.5971562931881804 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  7 \n",
      "\n",
      "Task 5 completed of iteration 6....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 7 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  8170 \n",
      "\n",
      "\t # of sent in y_pool:  8170 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  153 \n",
      "\n",
      "\t # of sent in y_train:  153 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.5905063997154176 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  8 \n",
      "\n",
      "f1 Score for testb is :  0.602563243196222 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  8 \n",
      "\n",
      "Task 5 completed of iteration 7....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 8 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  8160 \n",
      "\n",
      "\t # of sent in y_pool:  8160 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  163 \n",
      "\n",
      "\t # of sent in y_train:  163 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.5963210196587257 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  9 \n",
      "\n",
      "f1 Score for testb is :  0.6091612744661693 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  9 \n",
      "\n",
      "Task 5 completed of iteration 8....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 9 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  8150 \n",
      "\n",
      "\t # of sent in y_pool:  8150 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  173 \n",
      "\n",
      "\t # of sent in y_train:  173 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.5954980992621507 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  10 \n",
      "\n",
      "f1 Score for testb is :  0.6084415778639438 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  10 \n",
      "\n",
      "Task 5 completed of iteration 9....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 10 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  8140 \n",
      "\n",
      "\t # of sent in y_pool:  8140 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  183 \n",
      "\n",
      "\t # of sent in y_train:  183 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.5996318306375615 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  11 \n",
      "\n",
      "f1 Score for testb is :  0.6180206252631031 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  11 \n",
      "\n",
      "Task 5 completed of iteration 10....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 11 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  8130 \n",
      "\n",
      "\t # of sent in y_pool:  8130 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  193 \n",
      "\n",
      "\t # of sent in y_train:  193 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6111681635185505 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  12 \n",
      "\n",
      "f1 Score for testb is :  0.6308354882382393 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  12 \n",
      "\n",
      "Task 5 completed of iteration 11....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 12 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  8120 \n",
      "\n",
      "\t # of sent in y_pool:  8120 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  203 \n",
      "\n",
      "\t # of sent in y_train:  203 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6228514247977646 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  13 \n",
      "\n",
      "f1 Score for testb is :  0.631158645783008 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  13 \n",
      "\n",
      "Task 5 completed of iteration 12....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 13 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  8110 \n",
      "\n",
      "\t # of sent in y_pool:  8110 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  213 \n",
      "\n",
      "\t # of sent in y_train:  213 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6292601074084063 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  14 \n",
      "\n",
      "f1 Score for testb is :  0.6384615284076366 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  14 \n",
      "\n",
      "Task 5 completed of iteration 13....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 14 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  8100 \n",
      "\n",
      "\t # of sent in y_pool:  8100 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  223 \n",
      "\n",
      "\t # of sent in y_train:  223 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6404518948499957 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  15 \n",
      "\n",
      "f1 Score for testb is :  0.6422148880400678 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  15 \n",
      "\n",
      "Task 5 completed of iteration 14....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 15 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  8090 \n",
      "\n",
      "\t # of sent in y_pool:  8090 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  233 \n",
      "\n",
      "\t # of sent in y_train:  233 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.639288554541014 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  16 \n",
      "\n",
      "f1 Score for testb is :  0.6480238323634215 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  16 \n",
      "\n",
      "Task 5 completed of iteration 15....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 16 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  8080 \n",
      "\n",
      "\t # of sent in y_pool:  8080 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  243 \n",
      "\n",
      "\t # of sent in y_train:  243 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.628919491484947 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  17 \n",
      "\n",
      "f1 Score for testb is :  0.6522847953538634 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  17 \n",
      "\n",
      "Task 5 completed of iteration 16....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 17 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  8070 \n",
      "\n",
      "\t # of sent in y_pool:  8070 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  253 \n",
      "\n",
      "\t # of sent in y_train:  253 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6361874549273521 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  18 \n",
      "\n",
      "f1 Score for testb is :  0.6531756212268103 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  18 \n",
      "\n",
      "Task 5 completed of iteration 17....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 18 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  8060 \n",
      "\n",
      "\t # of sent in y_pool:  8060 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  263 \n",
      "\n",
      "\t # of sent in y_train:  263 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6354137700719977 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  19 \n",
      "\n",
      "f1 Score for testb is :  0.657897828882173 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  19 \n",
      "\n",
      "Task 5 completed of iteration 18....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 19 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  8050 \n",
      "\n",
      "\t # of sent in y_pool:  8050 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  273 \n",
      "\n",
      "\t # of sent in y_train:  273 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6414233688384532 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  20 \n",
      "\n",
      "f1 Score for testb is :  0.6645247321233195 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  20 \n",
      "\n",
      "Task 5 completed of iteration 19....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 20 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  8040 \n",
      "\n",
      "\t # of sent in y_pool:  8040 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  283 \n",
      "\n",
      "\t # of sent in y_train:  283 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6430752874740854 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  21 \n",
      "\n",
      "f1 Score for testb is :  0.6632198628990101 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  21 \n",
      "\n",
      "Task 5 completed of iteration 20....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 21 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  8030 \n",
      "\n",
      "\t # of sent in y_pool:  8030 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  293 \n",
      "\n",
      "\t # of sent in y_train:  293 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6455931033401605 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  22 \n",
      "\n",
      "f1 Score for testb is :  0.6674652544980415 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  22 \n",
      "\n",
      "Task 5 completed of iteration 21....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 22 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  8020 \n",
      "\n",
      "\t # of sent in y_pool:  8020 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  303 \n",
      "\n",
      "\t # of sent in y_train:  303 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6398969847807546 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  23 \n",
      "\n",
      "f1 Score for testb is :  0.6705075849100546 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  23 \n",
      "\n",
      "Task 5 completed of iteration 22....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 23 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  8010 \n",
      "\n",
      "\t # of sent in y_pool:  8010 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  313 \n",
      "\n",
      "\t # of sent in y_train:  313 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6479029570905778 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  24 \n",
      "\n",
      "f1 Score for testb is :  0.6690851922383579 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  24 \n",
      "\n",
      "Task 5 completed of iteration 23....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 24 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  8000 \n",
      "\n",
      "\t # of sent in y_pool:  8000 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  323 \n",
      "\n",
      "\t # of sent in y_train:  323 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6465037252780473 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  25 \n",
      "\n",
      "f1 Score for testb is :  0.6684344865507166 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  25 \n",
      "\n",
      "Task 5 completed of iteration 24....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 25 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7990 \n",
      "\n",
      "\t # of sent in y_pool:  7990 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  333 \n",
      "\n",
      "\t # of sent in y_train:  333 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6538595728580272 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  26 \n",
      "\n",
      "f1 Score for testb is :  0.6706223384924207 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  26 \n",
      "\n",
      "Task 5 completed of iteration 25....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 26 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7980 \n",
      "\n",
      "\t # of sent in y_pool:  7980 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  343 \n",
      "\n",
      "\t # of sent in y_train:  343 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6497653820261411 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  27 \n",
      "\n",
      "f1 Score for testb is :  0.6801552387411467 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  27 \n",
      "\n",
      "Task 5 completed of iteration 26....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 27 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7970 \n",
      "\n",
      "\t # of sent in y_pool:  7970 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  353 \n",
      "\n",
      "\t # of sent in y_train:  353 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6576478186193566 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  28 \n",
      "\n",
      "f1 Score for testb is :  0.6819499244391729 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  28 \n",
      "\n",
      "Task 5 completed of iteration 27....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 28 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7960 \n",
      "\n",
      "\t # of sent in y_pool:  7960 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  363 \n",
      "\n",
      "\t # of sent in y_train:  363 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6603794395900737 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  29 \n",
      "\n",
      "f1 Score for testb is :  0.6841980981522741 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  29 \n",
      "\n",
      "Task 5 completed of iteration 28....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 29 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7950 \n",
      "\n",
      "\t # of sent in y_pool:  7950 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  373 \n",
      "\n",
      "\t # of sent in y_train:  373 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6609742919522661 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  30 \n",
      "\n",
      "f1 Score for testb is :  0.6851932574211705 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  30 \n",
      "\n",
      "Task 5 completed of iteration 29....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 30 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7940 \n",
      "\n",
      "\t # of sent in y_pool:  7940 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  383 \n",
      "\n",
      "\t # of sent in y_train:  383 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6618053511010129 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  31 \n",
      "\n",
      "f1 Score for testb is :  0.687427726370402 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  31 \n",
      "\n",
      "Task 5 completed of iteration 30....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 31 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7930 \n",
      "\n",
      "\t # of sent in y_pool:  7930 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  393 \n",
      "\n",
      "\t # of sent in y_train:  393 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6541825300746087 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  32 \n",
      "\n",
      "f1 Score for testb is :  0.6895244871052194 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  32 \n",
      "\n",
      "Task 5 completed of iteration 31....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 32 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7920 \n",
      "\n",
      "\t # of sent in y_pool:  7920 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  403 \n",
      "\n",
      "\t # of sent in y_train:  403 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6632249228146029 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  33 \n",
      "\n",
      "f1 Score for testb is :  0.6899982416906261 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  33 \n",
      "\n",
      "Task 5 completed of iteration 32....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 33 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7910 \n",
      "\n",
      "\t # of sent in y_pool:  7910 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  413 \n",
      "\n",
      "\t # of sent in y_train:  413 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6593706539588193 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  34 \n",
      "\n",
      "f1 Score for testb is :  0.695681966233177 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  34 \n",
      "\n",
      "Task 5 completed of iteration 33....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 34 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7900 \n",
      "\n",
      "\t # of sent in y_pool:  7900 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  423 \n",
      "\n",
      "\t # of sent in y_train:  423 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6627261444984589 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  35 \n",
      "\n",
      "f1 Score for testb is :  0.7060166729465168 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  35 \n",
      "\n",
      "Task 5 completed of iteration 34....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 35 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7890 \n",
      "\n",
      "\t # of sent in y_pool:  7890 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  433 \n",
      "\n",
      "\t # of sent in y_train:  433 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6520370692124655 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  36 \n",
      "\n",
      "f1 Score for testb is :  0.7130976261227976 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  36 \n",
      "\n",
      "Task 5 completed of iteration 35....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 36 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7880 \n",
      "\n",
      "\t # of sent in y_pool:  7880 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  443 \n",
      "\n",
      "\t # of sent in y_train:  443 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.654403896479554 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  37 \n",
      "\n",
      "f1 Score for testb is :  0.7086409197773245 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  37 \n",
      "\n",
      "Task 5 completed of iteration 36....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 37 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7870 \n",
      "\n",
      "\t # of sent in y_pool:  7870 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  453 \n",
      "\n",
      "\t # of sent in y_train:  453 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6651404975280165 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  38 \n",
      "\n",
      "f1 Score for testb is :  0.7162078868243953 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  38 \n",
      "\n",
      "Task 5 completed of iteration 37....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 38 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7860 \n",
      "\n",
      "\t # of sent in y_pool:  7860 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  463 \n",
      "\n",
      "\t # of sent in y_train:  463 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6689991439072225 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  39 \n",
      "\n",
      "f1 Score for testb is :  0.7198697123723629 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  39 \n",
      "\n",
      "Task 5 completed of iteration 38....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 39 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7850 \n",
      "\n",
      "\t # of sent in y_pool:  7850 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  473 \n",
      "\n",
      "\t # of sent in y_train:  473 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6672751372893407 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  40 \n",
      "\n",
      "f1 Score for testb is :  0.7194905268840749 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  40 \n",
      "\n",
      "Task 5 completed of iteration 39....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 40 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7840 \n",
      "\n",
      "\t # of sent in y_pool:  7840 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  483 \n",
      "\n",
      "\t # of sent in y_train:  483 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6635973692781861 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  41 \n",
      "\n",
      "f1 Score for testb is :  0.7275583131469412 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  41 \n",
      "\n",
      "Task 5 completed of iteration 40....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 41 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7830 \n",
      "\n",
      "\t # of sent in y_pool:  7830 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  493 \n",
      "\n",
      "\t # of sent in y_train:  493 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6685225482469923 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  42 \n",
      "\n",
      "f1 Score for testb is :  0.7230104578087565 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  42 \n",
      "\n",
      "Task 5 completed of iteration 41....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 42 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7820 \n",
      "\n",
      "\t # of sent in y_pool:  7820 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  503 \n",
      "\n",
      "\t # of sent in y_train:  503 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6665313962231224 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  43 \n",
      "\n",
      "f1 Score for testb is :  0.7222437211842015 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  43 \n",
      "\n",
      "Task 5 completed of iteration 42....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 43 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7810 \n",
      "\n",
      "\t # of sent in y_pool:  7810 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  513 \n",
      "\n",
      "\t # of sent in y_train:  513 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6737215105939406 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  44 \n",
      "\n",
      "f1 Score for testb is :  0.7274489701254383 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  44 \n",
      "\n",
      "Task 5 completed of iteration 43....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 44 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7800 \n",
      "\n",
      "\t # of sent in y_pool:  7800 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  523 \n",
      "\n",
      "\t # of sent in y_train:  523 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6835304086222862 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  45 \n",
      "\n",
      "f1 Score for testb is :  0.7268802243643693 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  45 \n",
      "\n",
      "Task 5 completed of iteration 44....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 45 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7790 \n",
      "\n",
      "\t # of sent in y_pool:  7790 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  533 \n",
      "\n",
      "\t # of sent in y_train:  533 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6840051993914353 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  46 \n",
      "\n",
      "f1 Score for testb is :  0.7245968187358873 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  46 \n",
      "\n",
      "Task 5 completed of iteration 45....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 46 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7780 \n",
      "\n",
      "\t # of sent in y_pool:  7780 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  543 \n",
      "\n",
      "\t # of sent in y_train:  543 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6880952203980949 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  47 \n",
      "\n",
      "f1 Score for testb is :  0.7232145188380333 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  47 \n",
      "\n",
      "Task 5 completed of iteration 46....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 47 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7770 \n",
      "\n",
      "\t # of sent in y_pool:  7770 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  553 \n",
      "\n",
      "\t # of sent in y_train:  553 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6806216416801872 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  48 \n",
      "\n",
      "f1 Score for testb is :  0.7290865237351345 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  48 \n",
      "\n",
      "Task 5 completed of iteration 47....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 48 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7760 \n",
      "\n",
      "\t # of sent in y_pool:  7760 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  563 \n",
      "\n",
      "\t # of sent in y_train:  563 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6860087029426444 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  49 \n",
      "\n",
      "f1 Score for testb is :  0.7268857945003878 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  49 \n",
      "\n",
      "Task 5 completed of iteration 48....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 49 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7750 \n",
      "\n",
      "\t # of sent in y_pool:  7750 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  573 \n",
      "\n",
      "\t # of sent in y_train:  573 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.690592847609927 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  50 \n",
      "\n",
      "f1 Score for testb is :  0.733448125089082 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  50 \n",
      "\n",
      "Task 5 completed of iteration 49....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 50 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7740 \n",
      "\n",
      "\t # of sent in y_pool:  7740 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  583 \n",
      "\n",
      "\t # of sent in y_train:  583 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6875306262145033 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  51 \n",
      "\n",
      "f1 Score for testb is :  0.7324188013966981 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  51 \n",
      "\n",
      "Task 5 completed of iteration 50....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 51 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7730 \n",
      "\n",
      "\t # of sent in y_pool:  7730 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  593 \n",
      "\n",
      "\t # of sent in y_train:  593 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6914303018836546 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  52 \n",
      "\n",
      "f1 Score for testb is :  0.7333378294167883 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  52 \n",
      "\n",
      "Task 5 completed of iteration 51....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 52 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7720 \n",
      "\n",
      "\t # of sent in y_pool:  7720 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  603 \n",
      "\n",
      "\t # of sent in y_train:  603 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6978449003082554 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  53 \n",
      "\n",
      "f1 Score for testb is :  0.7380277949071361 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  53 \n",
      "\n",
      "Task 5 completed of iteration 52....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 53 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7710 \n",
      "\n",
      "\t # of sent in y_pool:  7710 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  613 \n",
      "\n",
      "\t # of sent in y_train:  613 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6912687502744524 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  54 \n",
      "\n",
      "f1 Score for testb is :  0.735039049699429 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  54 \n",
      "\n",
      "Task 5 completed of iteration 53....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 54 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7700 \n",
      "\n",
      "\t # of sent in y_pool:  7700 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  623 \n",
      "\n",
      "\t # of sent in y_train:  623 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6920835702869285 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  55 \n",
      "\n",
      "f1 Score for testb is :  0.7317800503166845 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  55 \n",
      "\n",
      "Task 5 completed of iteration 54....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 55 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7690 \n",
      "\n",
      "\t # of sent in y_pool:  7690 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  633 \n",
      "\n",
      "\t # of sent in y_train:  633 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6918529493315704 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  56 \n",
      "\n",
      "f1 Score for testb is :  0.7374134048037182 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  56 \n",
      "\n",
      "Task 5 completed of iteration 55....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 56 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7680 \n",
      "\n",
      "\t # of sent in y_pool:  7680 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  643 \n",
      "\n",
      "\t # of sent in y_train:  643 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6956864687782215 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  57 \n",
      "\n",
      "f1 Score for testb is :  0.7398142534457266 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  57 \n",
      "\n",
      "Task 5 completed of iteration 56....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 57 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7670 \n",
      "\n",
      "\t # of sent in y_pool:  7670 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  653 \n",
      "\n",
      "\t # of sent in y_train:  653 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6935984001250907 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  58 \n",
      "\n",
      "f1 Score for testb is :  0.7378478299837022 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  58 \n",
      "\n",
      "Task 5 completed of iteration 57....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 58 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7660 \n",
      "\n",
      "\t # of sent in y_pool:  7660 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  663 \n",
      "\n",
      "\t # of sent in y_train:  663 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6981133109274632 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  59 \n",
      "\n",
      "f1 Score for testb is :  0.7378166025967888 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  59 \n",
      "\n",
      "Task 5 completed of iteration 58....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 59 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7650 \n",
      "\n",
      "\t # of sent in y_pool:  7650 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  673 \n",
      "\n",
      "\t # of sent in y_train:  673 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6992121268455781 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  60 \n",
      "\n",
      "f1 Score for testb is :  0.7412965777064907 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  60 \n",
      "\n",
      "Task 5 completed of iteration 59....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 60 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7640 \n",
      "\n",
      "\t # of sent in y_pool:  7640 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  683 \n",
      "\n",
      "\t # of sent in y_train:  683 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6999407854707708 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  61 \n",
      "\n",
      "f1 Score for testb is :  0.7450209373156738 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  61 \n",
      "\n",
      "Task 5 completed of iteration 60....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 61 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7630 \n",
      "\n",
      "\t # of sent in y_pool:  7630 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  693 \n",
      "\n",
      "\t # of sent in y_train:  693 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.6979621422302089 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  62 \n",
      "\n",
      "f1 Score for testb is :  0.7461034115036181 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  62 \n",
      "\n",
      "Task 5 completed of iteration 61....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 62 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7620 \n",
      "\n",
      "\t # of sent in y_pool:  7620 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  703 \n",
      "\n",
      "\t # of sent in y_train:  703 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7055667932744889 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  63 \n",
      "\n",
      "f1 Score for testb is :  0.7464274011932177 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  63 \n",
      "\n",
      "Task 5 completed of iteration 62....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 63 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7610 \n",
      "\n",
      "\t # of sent in y_pool:  7610 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  713 \n",
      "\n",
      "\t # of sent in y_train:  713 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7030110457607257 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  64 \n",
      "\n",
      "f1 Score for testb is :  0.7443212082800249 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  64 \n",
      "\n",
      "Task 5 completed of iteration 63....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 64 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7600 \n",
      "\n",
      "\t # of sent in y_pool:  7600 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  723 \n",
      "\n",
      "\t # of sent in y_train:  723 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7034452595407109 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  65 \n",
      "\n",
      "f1 Score for testb is :  0.7460096138123891 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  65 \n",
      "\n",
      "Task 5 completed of iteration 64....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 65 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7590 \n",
      "\n",
      "\t # of sent in y_pool:  7590 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  733 \n",
      "\n",
      "\t # of sent in y_train:  733 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7076344840862568 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  66 \n",
      "\n",
      "f1 Score for testb is :  0.7500434409609003 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  66 \n",
      "\n",
      "Task 5 completed of iteration 65....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 66 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7580 \n",
      "\n",
      "\t # of sent in y_pool:  7580 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  743 \n",
      "\n",
      "\t # of sent in y_train:  743 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7090838736913849 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  67 \n",
      "\n",
      "f1 Score for testb is :  0.7472480928621215 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  67 \n",
      "\n",
      "Task 5 completed of iteration 66....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 67 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7570 \n",
      "\n",
      "\t # of sent in y_pool:  7570 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  753 \n",
      "\n",
      "\t # of sent in y_train:  753 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7090340412570088 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  68 \n",
      "\n",
      "f1 Score for testb is :  0.7522738097330419 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  68 \n",
      "\n",
      "Task 5 completed of iteration 67....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 68 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7560 \n",
      "\n",
      "\t # of sent in y_pool:  7560 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  763 \n",
      "\n",
      "\t # of sent in y_train:  763 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7123026624100333 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  69 \n",
      "\n",
      "f1 Score for testb is :  0.7494176961909692 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  69 \n",
      "\n",
      "Task 5 completed of iteration 68....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 69 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7550 \n",
      "\n",
      "\t # of sent in y_pool:  7550 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  773 \n",
      "\n",
      "\t # of sent in y_train:  773 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7136263226365472 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  70 \n",
      "\n",
      "f1 Score for testb is :  0.7495651649120054 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  70 \n",
      "\n",
      "Task 5 completed of iteration 69....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 70 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7540 \n",
      "\n",
      "\t # of sent in y_pool:  7540 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  783 \n",
      "\n",
      "\t # of sent in y_train:  783 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7132901677631974 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  71 \n",
      "\n",
      "f1 Score for testb is :  0.7518532695579864 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  71 \n",
      "\n",
      "Task 5 completed of iteration 70....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 71 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7530 \n",
      "\n",
      "\t # of sent in y_pool:  7530 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  793 \n",
      "\n",
      "\t # of sent in y_train:  793 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7082166615674685 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  72 \n",
      "\n",
      "f1 Score for testb is :  0.7512086574189828 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  72 \n",
      "\n",
      "Task 5 completed of iteration 71....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 72 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7520 \n",
      "\n",
      "\t # of sent in y_pool:  7520 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  803 \n",
      "\n",
      "\t # of sent in y_train:  803 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7121224393715622 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  73 \n",
      "\n",
      "f1 Score for testb is :  0.7520531767462316 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  73 \n",
      "\n",
      "Task 5 completed of iteration 72....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 73 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7510 \n",
      "\n",
      "\t # of sent in y_pool:  7510 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  813 \n",
      "\n",
      "\t # of sent in y_train:  813 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7180368076160463 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  74 \n",
      "\n",
      "f1 Score for testb is :  0.7535247943510601 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  74 \n",
      "\n",
      "Task 5 completed of iteration 73....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 74 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7500 \n",
      "\n",
      "\t # of sent in y_pool:  7500 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  823 \n",
      "\n",
      "\t # of sent in y_train:  823 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7147017074720047 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  75 \n",
      "\n",
      "f1 Score for testb is :  0.7587959473042665 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  75 \n",
      "\n",
      "Task 5 completed of iteration 74....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 75 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7490 \n",
      "\n",
      "\t # of sent in y_pool:  7490 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  833 \n",
      "\n",
      "\t # of sent in y_train:  833 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7127890332070697 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  76 \n",
      "\n",
      "f1 Score for testb is :  0.7599525744230244 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  76 \n",
      "\n",
      "Task 5 completed of iteration 75....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 76 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7480 \n",
      "\n",
      "\t # of sent in y_pool:  7480 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  843 \n",
      "\n",
      "\t # of sent in y_train:  843 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7136569300343443 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  77 \n",
      "\n",
      "f1 Score for testb is :  0.7584825934979812 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  77 \n",
      "\n",
      "Task 5 completed of iteration 76....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 77 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7470 \n",
      "\n",
      "\t # of sent in y_pool:  7470 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  853 \n",
      "\n",
      "\t # of sent in y_train:  853 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7190352000189751 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  78 \n",
      "\n",
      "f1 Score for testb is :  0.7655484049403553 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  78 \n",
      "\n",
      "Task 5 completed of iteration 77....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 78 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7460 \n",
      "\n",
      "\t # of sent in y_pool:  7460 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  863 \n",
      "\n",
      "\t # of sent in y_train:  863 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7161113644613122 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  79 \n",
      "\n",
      "f1 Score for testb is :  0.7610303631945764 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  79 \n",
      "\n",
      "Task 5 completed of iteration 78....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 79 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7450 \n",
      "\n",
      "\t # of sent in y_pool:  7450 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  873 \n",
      "\n",
      "\t # of sent in y_train:  873 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7165038423503083 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  80 \n",
      "\n",
      "f1 Score for testb is :  0.759828036594581 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  80 \n",
      "\n",
      "Task 5 completed of iteration 79....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 80 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7440 \n",
      "\n",
      "\t # of sent in y_pool:  7440 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  883 \n",
      "\n",
      "\t # of sent in y_train:  883 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7164627905664231 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  81 \n",
      "\n",
      "f1 Score for testb is :  0.7631350908720543 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  81 \n",
      "\n",
      "Task 5 completed of iteration 80....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 81 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7430 \n",
      "\n",
      "\t # of sent in y_pool:  7430 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  893 \n",
      "\n",
      "\t # of sent in y_train:  893 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7159275897761539 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  82 \n",
      "\n",
      "f1 Score for testb is :  0.7641366838266934 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  82 \n",
      "\n",
      "Task 5 completed of iteration 81....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 82 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7420 \n",
      "\n",
      "\t # of sent in y_pool:  7420 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  903 \n",
      "\n",
      "\t # of sent in y_train:  903 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7184250732542221 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  83 \n",
      "\n",
      "f1 Score for testb is :  0.7628731631272455 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  83 \n",
      "\n",
      "Task 5 completed of iteration 82....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 83 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7410 \n",
      "\n",
      "\t # of sent in y_pool:  7410 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  913 \n",
      "\n",
      "\t # of sent in y_train:  913 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7200357631280412 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  84 \n",
      "\n",
      "f1 Score for testb is :  0.7661541985875159 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  84 \n",
      "\n",
      "Task 5 completed of iteration 83....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 84 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7400 \n",
      "\n",
      "\t # of sent in y_pool:  7400 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  923 \n",
      "\n",
      "\t # of sent in y_train:  923 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7251081376655942 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  85 \n",
      "\n",
      "f1 Score for testb is :  0.7621063086849605 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  85 \n",
      "\n",
      "Task 5 completed of iteration 84....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 85 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7390 \n",
      "\n",
      "\t # of sent in y_pool:  7390 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  933 \n",
      "\n",
      "\t # of sent in y_train:  933 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7333310534509498 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  86 \n",
      "\n",
      "f1 Score for testb is :  0.7662925855296898 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  86 \n",
      "\n",
      "Task 5 completed of iteration 85....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 86 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7380 \n",
      "\n",
      "\t # of sent in y_pool:  7380 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  943 \n",
      "\n",
      "\t # of sent in y_train:  943 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7282670791453917 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  87 \n",
      "\n",
      "f1 Score for testb is :  0.7615853328448379 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  87 \n",
      "\n",
      "Task 5 completed of iteration 86....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 87 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7370 \n",
      "\n",
      "\t # of sent in y_pool:  7370 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  953 \n",
      "\n",
      "\t # of sent in y_train:  953 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.727662082621982 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  88 \n",
      "\n",
      "f1 Score for testb is :  0.7639309921904889 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  88 \n",
      "\n",
      "Task 5 completed of iteration 87....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 88 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7360 \n",
      "\n",
      "\t # of sent in y_pool:  7360 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  963 \n",
      "\n",
      "\t # of sent in y_train:  963 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7263858013473716 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  89 \n",
      "\n",
      "f1 Score for testb is :  0.7594871309972041 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  89 \n",
      "\n",
      "Task 5 completed of iteration 88....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 89 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7350 \n",
      "\n",
      "\t # of sent in y_pool:  7350 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  973 \n",
      "\n",
      "\t # of sent in y_train:  973 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7345149981535202 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  90 \n",
      "\n",
      "f1 Score for testb is :  0.7632148467388058 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  90 \n",
      "\n",
      "Task 5 completed of iteration 89....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 90 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7340 \n",
      "\n",
      "\t # of sent in y_pool:  7340 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  983 \n",
      "\n",
      "\t # of sent in y_train:  983 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7286664465671876 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  91 \n",
      "\n",
      "f1 Score for testb is :  0.7658034472347252 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  91 \n",
      "\n",
      "Task 5 completed of iteration 90....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 91 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7330 \n",
      "\n",
      "\t # of sent in y_pool:  7330 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  993 \n",
      "\n",
      "\t # of sent in y_train:  993 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7269496437208686 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  92 \n",
      "\n",
      "f1 Score for testb is :  0.7615540229656304 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  92 \n",
      "\n",
      "Task 5 completed of iteration 91....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 92 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7320 \n",
      "\n",
      "\t # of sent in y_pool:  7320 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1003 \n",
      "\n",
      "\t # of sent in y_train:  1003 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7330169156714238 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  93 \n",
      "\n",
      "f1 Score for testb is :  0.7659008671706237 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  93 \n",
      "\n",
      "Task 5 completed of iteration 92....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 93 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7310 \n",
      "\n",
      "\t # of sent in y_pool:  7310 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1013 \n",
      "\n",
      "\t # of sent in y_train:  1013 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7303643053110251 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  94 \n",
      "\n",
      "f1 Score for testb is :  0.7623863738397757 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  94 \n",
      "\n",
      "Task 5 completed of iteration 93....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 94 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7300 \n",
      "\n",
      "\t # of sent in y_pool:  7300 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1023 \n",
      "\n",
      "\t # of sent in y_train:  1023 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7315470376491738 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  95 \n",
      "\n",
      "f1 Score for testb is :  0.7656530073508431 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  95 \n",
      "\n",
      "Task 5 completed of iteration 94....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 95 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7290 \n",
      "\n",
      "\t # of sent in y_pool:  7290 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1033 \n",
      "\n",
      "\t # of sent in y_train:  1033 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7374884384634178 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  96 \n",
      "\n",
      "f1 Score for testb is :  0.7650279257681196 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  96 \n",
      "\n",
      "Task 5 completed of iteration 95....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 96 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7280 \n",
      "\n",
      "\t # of sent in y_pool:  7280 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1043 \n",
      "\n",
      "\t # of sent in y_train:  1043 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7318558792214371 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  97 \n",
      "\n",
      "f1 Score for testb is :  0.7672729103575568 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  97 \n",
      "\n",
      "Task 5 completed of iteration 96....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 97 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7270 \n",
      "\n",
      "\t # of sent in y_pool:  7270 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1053 \n",
      "\n",
      "\t # of sent in y_train:  1053 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7411801434120594 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  98 \n",
      "\n",
      "f1 Score for testb is :  0.7648703782313498 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  98 \n",
      "\n",
      "Task 5 completed of iteration 97....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 98 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7260 \n",
      "\n",
      "\t # of sent in y_pool:  7260 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1063 \n",
      "\n",
      "\t # of sent in y_train:  1063 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.739980001117083 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  99 \n",
      "\n",
      "f1 Score for testb is :  0.766537535626984 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  99 \n",
      "\n",
      "Task 5 completed of iteration 98....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 99 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7250 \n",
      "\n",
      "\t # of sent in y_pool:  7250 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1073 \n",
      "\n",
      "\t # of sent in y_train:  1073 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7391332548106486 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  100 \n",
      "\n",
      "f1 Score for testb is :  0.7628273301135242 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  100 \n",
      "\n",
      "Task 5 completed of iteration 99....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 100 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7240 \n",
      "\n",
      "\t # of sent in y_pool:  7240 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1083 \n",
      "\n",
      "\t # of sent in y_train:  1083 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.738116375958857 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  101 \n",
      "\n",
      "f1 Score for testb is :  0.7606183726815824 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  101 \n",
      "\n",
      "Task 5 completed of iteration 100....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 101 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7230 \n",
      "\n",
      "\t # of sent in y_pool:  7230 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1093 \n",
      "\n",
      "\t # of sent in y_train:  1093 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7408429627808928 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  102 \n",
      "\n",
      "f1 Score for testb is :  0.764093187368679 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  102 \n",
      "\n",
      "Task 5 completed of iteration 101....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 102 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7220 \n",
      "\n",
      "\t # of sent in y_pool:  7220 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1103 \n",
      "\n",
      "\t # of sent in y_train:  1103 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7373172947777561 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  103 \n",
      "\n",
      "f1 Score for testb is :  0.7609624323275745 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  103 \n",
      "\n",
      "Task 5 completed of iteration 102....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 103 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7210 \n",
      "\n",
      "\t # of sent in y_pool:  7210 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1113 \n",
      "\n",
      "\t # of sent in y_train:  1113 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7403941084208137 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  104 \n",
      "\n",
      "f1 Score for testb is :  0.7658619442981965 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  104 \n",
      "\n",
      "Task 5 completed of iteration 103....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 104 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7200 \n",
      "\n",
      "\t # of sent in y_pool:  7200 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1123 \n",
      "\n",
      "\t # of sent in y_train:  1123 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7386688561155353 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  105 \n",
      "\n",
      "f1 Score for testb is :  0.7664157734082794 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  105 \n",
      "\n",
      "Task 5 completed of iteration 104....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 105 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7190 \n",
      "\n",
      "\t # of sent in y_pool:  7190 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1133 \n",
      "\n",
      "\t # of sent in y_train:  1133 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7423544583996402 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  106 \n",
      "\n",
      "f1 Score for testb is :  0.764746764318589 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  106 \n",
      "\n",
      "Task 5 completed of iteration 105....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 106 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7180 \n",
      "\n",
      "\t # of sent in y_pool:  7180 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1143 \n",
      "\n",
      "\t # of sent in y_train:  1143 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7403042063286333 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  107 \n",
      "\n",
      "f1 Score for testb is :  0.7694418846247498 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  107 \n",
      "\n",
      "Task 5 completed of iteration 106....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 107 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7170 \n",
      "\n",
      "\t # of sent in y_pool:  7170 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1153 \n",
      "\n",
      "\t # of sent in y_train:  1153 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7419213722544509 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  108 \n",
      "\n",
      "f1 Score for testb is :  0.767980096279705 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  108 \n",
      "\n",
      "Task 5 completed of iteration 107....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 108 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7160 \n",
      "\n",
      "\t # of sent in y_pool:  7160 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1163 \n",
      "\n",
      "\t # of sent in y_train:  1163 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7382196531825774 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  109 \n",
      "\n",
      "f1 Score for testb is :  0.7745548955473843 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  109 \n",
      "\n",
      "Task 5 completed of iteration 108....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 109 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7150 \n",
      "\n",
      "\t # of sent in y_pool:  7150 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1173 \n",
      "\n",
      "\t # of sent in y_train:  1173 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.744137159163926 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  110 \n",
      "\n",
      "f1 Score for testb is :  0.7718083942690259 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  110 \n",
      "\n",
      "Task 5 completed of iteration 109....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 110 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7140 \n",
      "\n",
      "\t # of sent in y_pool:  7140 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1183 \n",
      "\n",
      "\t # of sent in y_train:  1183 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7432858657994158 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  111 \n",
      "\n",
      "f1 Score for testb is :  0.7737263972283129 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  111 \n",
      "\n",
      "Task 5 completed of iteration 110....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 111 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7130 \n",
      "\n",
      "\t # of sent in y_pool:  7130 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1193 \n",
      "\n",
      "\t # of sent in y_train:  1193 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7435974989941487 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  112 \n",
      "\n",
      "f1 Score for testb is :  0.7729152387302878 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  112 \n",
      "\n",
      "Task 5 completed of iteration 111....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 112 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7120 \n",
      "\n",
      "\t # of sent in y_pool:  7120 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1203 \n",
      "\n",
      "\t # of sent in y_train:  1203 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7402703432657626 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  113 \n",
      "\n",
      "f1 Score for testb is :  0.7737100689488539 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  113 \n",
      "\n",
      "Task 5 completed of iteration 112....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 113 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7110 \n",
      "\n",
      "\t # of sent in y_pool:  7110 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1213 \n",
      "\n",
      "\t # of sent in y_train:  1213 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7402216137254964 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  114 \n",
      "\n",
      "f1 Score for testb is :  0.7709257157631917 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  114 \n",
      "\n",
      "Task 5 completed of iteration 113....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 114 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7100 \n",
      "\n",
      "\t # of sent in y_pool:  7100 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1223 \n",
      "\n",
      "\t # of sent in y_train:  1223 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7385608778835201 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  115 \n",
      "\n",
      "f1 Score for testb is :  0.7752436371457265 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  115 \n",
      "\n",
      "Task 5 completed of iteration 114....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 115 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7090 \n",
      "\n",
      "\t # of sent in y_pool:  7090 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1233 \n",
      "\n",
      "\t # of sent in y_train:  1233 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7403187053949835 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  116 \n",
      "\n",
      "f1 Score for testb is :  0.7763837697250926 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  116 \n",
      "\n",
      "Task 5 completed of iteration 115....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 116 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7080 \n",
      "\n",
      "\t # of sent in y_pool:  7080 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1243 \n",
      "\n",
      "\t # of sent in y_train:  1243 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7369669278721821 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  117 \n",
      "\n",
      "f1 Score for testb is :  0.7750746545014334 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  117 \n",
      "\n",
      "Task 5 completed of iteration 116....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 117 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7070 \n",
      "\n",
      "\t # of sent in y_pool:  7070 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1253 \n",
      "\n",
      "\t # of sent in y_train:  1253 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7380498446973147 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  118 \n",
      "\n",
      "f1 Score for testb is :  0.7753764786745134 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  118 \n",
      "\n",
      "Task 5 completed of iteration 117....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 118 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7060 \n",
      "\n",
      "\t # of sent in y_pool:  7060 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1263 \n",
      "\n",
      "\t # of sent in y_train:  1263 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.737597779178076 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  119 \n",
      "\n",
      "f1 Score for testb is :  0.7719202735606014 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  119 \n",
      "\n",
      "Task 5 completed of iteration 118....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 119 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7050 \n",
      "\n",
      "\t # of sent in y_pool:  7050 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1273 \n",
      "\n",
      "\t # of sent in y_train:  1273 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.742153998474807 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  120 \n",
      "\n",
      "f1 Score for testb is :  0.7759318187090216 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  120 \n",
      "\n",
      "Task 5 completed of iteration 119....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 120 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7040 \n",
      "\n",
      "\t # of sent in y_pool:  7040 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1283 \n",
      "\n",
      "\t # of sent in y_train:  1283 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 Score for testa is :  0.7382412045641976 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  121 \n",
      "\n",
      "f1 Score for testb is :  0.7746336164961902 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  121 \n",
      "\n",
      "Task 5 completed of iteration 120....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 121 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7030 \n",
      "\n",
      "\t # of sent in y_pool:  7030 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1293 \n",
      "\n",
      "\t # of sent in y_train:  1293 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7393084087235309 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  122 \n",
      "\n",
      "f1 Score for testb is :  0.7782315977668737 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  122 \n",
      "\n",
      "Task 5 completed of iteration 121....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 122 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7020 \n",
      "\n",
      "\t # of sent in y_pool:  7020 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1303 \n",
      "\n",
      "\t # of sent in y_train:  1303 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7411793925706509 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  123 \n",
      "\n",
      "f1 Score for testb is :  0.7769505995602831 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  123 \n",
      "\n",
      "Task 5 completed of iteration 122....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 123 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7010 \n",
      "\n",
      "\t # of sent in y_pool:  7010 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1313 \n",
      "\n",
      "\t # of sent in y_train:  1313 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7437776809783633 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  124 \n",
      "\n",
      "f1 Score for testb is :  0.7774148916004386 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  124 \n",
      "\n",
      "Task 5 completed of iteration 123....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 124 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  7000 \n",
      "\n",
      "\t # of sent in y_pool:  7000 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1323 \n",
      "\n",
      "\t # of sent in y_train:  1323 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7408662057988308 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  125 \n",
      "\n",
      "f1 Score for testb is :  0.7779491260802689 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  125 \n",
      "\n",
      "Task 5 completed of iteration 124....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 125 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6990 \n",
      "\n",
      "\t # of sent in y_pool:  6990 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1333 \n",
      "\n",
      "\t # of sent in y_train:  1333 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7432137421218096 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  126 \n",
      "\n",
      "f1 Score for testb is :  0.7793346574232212 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  126 \n",
      "\n",
      "Task 5 completed of iteration 125....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 126 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6980 \n",
      "\n",
      "\t # of sent in y_pool:  6980 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1343 \n",
      "\n",
      "\t # of sent in y_train:  1343 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7454253402285499 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  127 \n",
      "\n",
      "f1 Score for testb is :  0.7833682914538803 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  127 \n",
      "\n",
      "Task 5 completed of iteration 126....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 127 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6970 \n",
      "\n",
      "\t # of sent in y_pool:  6970 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1353 \n",
      "\n",
      "\t # of sent in y_train:  1353 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7416217715982031 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  128 \n",
      "\n",
      "f1 Score for testb is :  0.7784671522245231 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  128 \n",
      "\n",
      "Task 5 completed of iteration 127....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 128 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6960 \n",
      "\n",
      "\t # of sent in y_pool:  6960 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1363 \n",
      "\n",
      "\t # of sent in y_train:  1363 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7486670834125315 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  129 \n",
      "\n",
      "f1 Score for testb is :  0.7836745216542709 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  129 \n",
      "\n",
      "Task 5 completed of iteration 128....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 129 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6950 \n",
      "\n",
      "\t # of sent in y_pool:  6950 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1373 \n",
      "\n",
      "\t # of sent in y_train:  1373 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7479836013769202 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  130 \n",
      "\n",
      "f1 Score for testb is :  0.7789073393610978 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  130 \n",
      "\n",
      "Task 5 completed of iteration 129....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 130 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6940 \n",
      "\n",
      "\t # of sent in y_pool:  6940 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1383 \n",
      "\n",
      "\t # of sent in y_train:  1383 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7490072076847982 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  131 \n",
      "\n",
      "f1 Score for testb is :  0.7784105204858205 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  131 \n",
      "\n",
      "Task 5 completed of iteration 130....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 131 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6930 \n",
      "\n",
      "\t # of sent in y_pool:  6930 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1393 \n",
      "\n",
      "\t # of sent in y_train:  1393 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7456323861026778 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  132 \n",
      "\n",
      "f1 Score for testb is :  0.785240258937689 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  132 \n",
      "\n",
      "Task 5 completed of iteration 131....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 132 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6920 \n",
      "\n",
      "\t # of sent in y_pool:  6920 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1403 \n",
      "\n",
      "\t # of sent in y_train:  1403 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7468179231770976 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  133 \n",
      "\n",
      "f1 Score for testb is :  0.7841776410894677 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  133 \n",
      "\n",
      "Task 5 completed of iteration 132....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 133 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6910 \n",
      "\n",
      "\t # of sent in y_pool:  6910 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1413 \n",
      "\n",
      "\t # of sent in y_train:  1413 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.740706625018219 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  134 \n",
      "\n",
      "f1 Score for testb is :  0.7815852259923647 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  134 \n",
      "\n",
      "Task 5 completed of iteration 133....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 134 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6900 \n",
      "\n",
      "\t # of sent in y_pool:  6900 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1423 \n",
      "\n",
      "\t # of sent in y_train:  1423 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7424206338045257 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  135 \n",
      "\n",
      "f1 Score for testb is :  0.7848662367027912 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  135 \n",
      "\n",
      "Task 5 completed of iteration 134....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 135 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6890 \n",
      "\n",
      "\t # of sent in y_pool:  6890 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1433 \n",
      "\n",
      "\t # of sent in y_train:  1433 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7507934275837492 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  136 \n",
      "\n",
      "f1 Score for testb is :  0.7827688225028935 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  136 \n",
      "\n",
      "Task 5 completed of iteration 135....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 136 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6880 \n",
      "\n",
      "\t # of sent in y_pool:  6880 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1443 \n",
      "\n",
      "\t # of sent in y_train:  1443 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7481350377729813 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  137 \n",
      "\n",
      "f1 Score for testb is :  0.7805741104768776 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  137 \n",
      "\n",
      "Task 5 completed of iteration 136....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 137 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6870 \n",
      "\n",
      "\t # of sent in y_pool:  6870 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1453 \n",
      "\n",
      "\t # of sent in y_train:  1453 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7449733996017828 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  138 \n",
      "\n",
      "f1 Score for testb is :  0.7867919394106051 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  138 \n",
      "\n",
      "Task 5 completed of iteration 137....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 138 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6860 \n",
      "\n",
      "\t # of sent in y_pool:  6860 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1463 \n",
      "\n",
      "\t # of sent in y_train:  1463 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7459919223776612 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  139 \n",
      "\n",
      "f1 Score for testb is :  0.7824703176966054 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  139 \n",
      "\n",
      "Task 5 completed of iteration 138....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 139 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6850 \n",
      "\n",
      "\t # of sent in y_pool:  6850 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1473 \n",
      "\n",
      "\t # of sent in y_train:  1473 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7453269560727847 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  140 \n",
      "\n",
      "f1 Score for testb is :  0.7831162965346389 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  140 \n",
      "\n",
      "Task 5 completed of iteration 139....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 140 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6840 \n",
      "\n",
      "\t # of sent in y_pool:  6840 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1483 \n",
      "\n",
      "\t # of sent in y_train:  1483 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7483840246142386 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  141 \n",
      "\n",
      "f1 Score for testb is :  0.785735043230537 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  141 \n",
      "\n",
      "Task 5 completed of iteration 140....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 141 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6830 \n",
      "\n",
      "\t # of sent in y_pool:  6830 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1493 \n",
      "\n",
      "\t # of sent in y_train:  1493 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.749048398439147 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  142 \n",
      "\n",
      "f1 Score for testb is :  0.786908583716792 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  142 \n",
      "\n",
      "Task 5 completed of iteration 141....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 142 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6820 \n",
      "\n",
      "\t # of sent in y_pool:  6820 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1503 \n",
      "\n",
      "\t # of sent in y_train:  1503 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7535940183681846 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  143 \n",
      "\n",
      "f1 Score for testb is :  0.787878794264516 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  143 \n",
      "\n",
      "Task 5 completed of iteration 142....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 143 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6810 \n",
      "\n",
      "\t # of sent in y_pool:  6810 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1513 \n",
      "\n",
      "\t # of sent in y_train:  1513 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7501506592484368 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  144 \n",
      "\n",
      "f1 Score for testb is :  0.7880440995917598 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  144 \n",
      "\n",
      "Task 5 completed of iteration 143....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 144 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6800 \n",
      "\n",
      "\t # of sent in y_pool:  6800 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1523 \n",
      "\n",
      "\t # of sent in y_train:  1523 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7476882805497225 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  145 \n",
      "\n",
      "f1 Score for testb is :  0.7869532963906196 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  145 \n",
      "\n",
      "Task 5 completed of iteration 144....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 145 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6790 \n",
      "\n",
      "\t # of sent in y_pool:  6790 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1533 \n",
      "\n",
      "\t # of sent in y_train:  1533 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7499665625076235 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  146 \n",
      "\n",
      "f1 Score for testb is :  0.7871551882728743 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  146 \n",
      "\n",
      "Task 5 completed of iteration 145....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 146 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6780 \n",
      "\n",
      "\t # of sent in y_pool:  6780 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1543 \n",
      "\n",
      "\t # of sent in y_train:  1543 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7557810283427485 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  147 \n",
      "\n",
      "f1 Score for testb is :  0.7860720965747017 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  147 \n",
      "\n",
      "Task 5 completed of iteration 146....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 147 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6770 \n",
      "\n",
      "\t # of sent in y_pool:  6770 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1553 \n",
      "\n",
      "\t # of sent in y_train:  1553 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7529929806888586 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  148 \n",
      "\n",
      "f1 Score for testb is :  0.7861360893896526 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  148 \n",
      "\n",
      "Task 5 completed of iteration 147....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 148 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6760 \n",
      "\n",
      "\t # of sent in y_pool:  6760 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1563 \n",
      "\n",
      "\t # of sent in y_train:  1563 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7503666362780563 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  149 \n",
      "\n",
      "f1 Score for testb is :  0.7900062572265767 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  149 \n",
      "\n",
      "Task 5 completed of iteration 148....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 149 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6750 \n",
      "\n",
      "\t # of sent in y_pool:  6750 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1573 \n",
      "\n",
      "\t # of sent in y_train:  1573 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7540581461973839 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  150 \n",
      "\n",
      "f1 Score for testb is :  0.788200350659727 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  150 \n",
      "\n",
      "Task 5 completed of iteration 149....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 150 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6740 \n",
      "\n",
      "\t # of sent in y_pool:  6740 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1583 \n",
      "\n",
      "\t # of sent in y_train:  1583 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7507960986146787 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  151 \n",
      "\n",
      "f1 Score for testb is :  0.7891119680328789 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  151 \n",
      "\n",
      "Task 5 completed of iteration 150....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 151 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6730 \n",
      "\n",
      "\t # of sent in y_pool:  6730 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1593 \n",
      "\n",
      "\t # of sent in y_train:  1593 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7498986182526421 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  152 \n",
      "\n",
      "f1 Score for testb is :  0.7912789289849541 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  152 \n",
      "\n",
      "Task 5 completed of iteration 151....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 152 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6720 \n",
      "\n",
      "\t # of sent in y_pool:  6720 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1603 \n",
      "\n",
      "\t # of sent in y_train:  1603 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 Score for testa is :  0.7435308475655454 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  153 \n",
      "\n",
      "f1 Score for testb is :  0.7898546893365097 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  153 \n",
      "\n",
      "Task 5 completed of iteration 152....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 153 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6710 \n",
      "\n",
      "\t # of sent in y_pool:  6710 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1613 \n",
      "\n",
      "\t # of sent in y_train:  1613 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7482213357730969 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  154 \n",
      "\n",
      "f1 Score for testb is :  0.7895541897972568 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  154 \n",
      "\n",
      "Task 5 completed of iteration 153....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 154 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6700 \n",
      "\n",
      "\t # of sent in y_pool:  6700 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1623 \n",
      "\n",
      "\t # of sent in y_train:  1623 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7481495080475474 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  155 \n",
      "\n",
      "f1 Score for testb is :  0.7964464482577599 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  155 \n",
      "\n",
      "Task 5 completed of iteration 154....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 155 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6690 \n",
      "\n",
      "\t # of sent in y_pool:  6690 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1633 \n",
      "\n",
      "\t # of sent in y_train:  1633 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7499527394543296 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  156 \n",
      "\n",
      "f1 Score for testb is :  0.7910629379270973 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  156 \n",
      "\n",
      "Task 5 completed of iteration 155....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 156 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6680 \n",
      "\n",
      "\t # of sent in y_pool:  6680 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1643 \n",
      "\n",
      "\t # of sent in y_train:  1643 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.749543521464047 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  157 \n",
      "\n",
      "f1 Score for testb is :  0.7912705657120066 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  157 \n",
      "\n",
      "Task 5 completed of iteration 156....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 157 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6670 \n",
      "\n",
      "\t # of sent in y_pool:  6670 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1653 \n",
      "\n",
      "\t # of sent in y_train:  1653 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7588942097552897 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  158 \n",
      "\n",
      "f1 Score for testb is :  0.7946357725750148 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  158 \n",
      "\n",
      "Task 5 completed of iteration 157....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 158 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6660 \n",
      "\n",
      "\t # of sent in y_pool:  6660 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1663 \n",
      "\n",
      "\t # of sent in y_train:  1663 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7540626747404493 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  159 \n",
      "\n",
      "f1 Score for testb is :  0.7916745779382335 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  159 \n",
      "\n",
      "Task 5 completed of iteration 158....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 159 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6650 \n",
      "\n",
      "\t # of sent in y_pool:  6650 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1673 \n",
      "\n",
      "\t # of sent in y_train:  1673 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7572840831270093 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  160 \n",
      "\n",
      "f1 Score for testb is :  0.7883043512640454 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  160 \n",
      "\n",
      "Task 5 completed of iteration 159....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 160 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6640 \n",
      "\n",
      "\t # of sent in y_pool:  6640 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1683 \n",
      "\n",
      "\t # of sent in y_train:  1683 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7575011632735087 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  161 \n",
      "\n",
      "f1 Score for testb is :  0.7941150592167864 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  161 \n",
      "\n",
      "Task 5 completed of iteration 160....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 161 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6630 \n",
      "\n",
      "\t # of sent in y_pool:  6630 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1693 \n",
      "\n",
      "\t # of sent in y_train:  1693 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7537220573218036 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  162 \n",
      "\n",
      "f1 Score for testb is :  0.7904732003209928 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  162 \n",
      "\n",
      "Task 5 completed of iteration 161....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 162 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6620 \n",
      "\n",
      "\t # of sent in y_pool:  6620 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1703 \n",
      "\n",
      "\t # of sent in y_train:  1703 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7604072956600291 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  163 \n",
      "\n",
      "f1 Score for testb is :  0.7989242697042568 \n",
      "\n",
      "\n",
      "len of prdict_f1_testb  163 \n",
      "\n",
      "Task 5 completed of iteration 162....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 163 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6610 \n",
      "\n",
      "\t # of sent in y_pool:  6610 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1713 \n",
      "\n",
      "\t # of sent in y_train:  1713 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7587080397030213 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  164 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 163....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 164 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6600 \n",
      "\n",
      "\t # of sent in y_pool:  6600 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1723 \n",
      "\n",
      "\t # of sent in y_train:  1723 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7591910811195973 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  165 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 164....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 165 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6590 \n",
      "\n",
      "\t # of sent in y_pool:  6590 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1733 \n",
      "\n",
      "\t # of sent in y_train:  1733 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7562948082841201 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  166 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 165....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 166 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6580 \n",
      "\n",
      "\t # of sent in y_pool:  6580 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1743 \n",
      "\n",
      "\t # of sent in y_train:  1743 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7608640140115089 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  167 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 166....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 167 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6570 \n",
      "\n",
      "\t # of sent in y_pool:  6570 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1753 \n",
      "\n",
      "\t # of sent in y_train:  1753 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7585716129140158 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  168 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 167....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 168 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6560 \n",
      "\n",
      "\t # of sent in y_pool:  6560 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1763 \n",
      "\n",
      "\t # of sent in y_train:  1763 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7606091573943035 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  169 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 168....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 169 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6550 \n",
      "\n",
      "\t # of sent in y_pool:  6550 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1773 \n",
      "\n",
      "\t # of sent in y_train:  1773 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7512198746669349 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  170 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 169....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 170 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6540 \n",
      "\n",
      "\t # of sent in y_pool:  6540 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1783 \n",
      "\n",
      "\t # of sent in y_train:  1783 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7560583443803774 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  171 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 170....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 171 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6530 \n",
      "\n",
      "\t # of sent in y_pool:  6530 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1793 \n",
      "\n",
      "\t # of sent in y_train:  1793 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7594429904305164 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  172 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 171....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 172 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6520 \n",
      "\n",
      "\t # of sent in y_pool:  6520 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1803 \n",
      "\n",
      "\t # of sent in y_train:  1803 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7546894109397465 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  173 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 172....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 173 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6510 \n",
      "\n",
      "\t # of sent in y_pool:  6510 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1813 \n",
      "\n",
      "\t # of sent in y_train:  1813 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7622885490951106 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  174 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 173....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 174 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6500 \n",
      "\n",
      "\t # of sent in y_pool:  6500 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1823 \n",
      "\n",
      "\t # of sent in y_train:  1823 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7561447230376287 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  175 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 174....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 175 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6490 \n",
      "\n",
      "\t # of sent in y_pool:  6490 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1833 \n",
      "\n",
      "\t # of sent in y_train:  1833 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7524259032907543 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  176 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 175....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 176 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6480 \n",
      "\n",
      "\t # of sent in y_pool:  6480 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1843 \n",
      "\n",
      "\t # of sent in y_train:  1843 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7569955404447745 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  177 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 176....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 177 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6470 \n",
      "\n",
      "\t # of sent in y_pool:  6470 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1853 \n",
      "\n",
      "\t # of sent in y_train:  1853 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7563256585615815 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  178 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 177....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 178 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6460 \n",
      "\n",
      "\t # of sent in y_pool:  6460 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1863 \n",
      "\n",
      "\t # of sent in y_train:  1863 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7550403052427146 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  179 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 178....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 179 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6450 \n",
      "\n",
      "\t # of sent in y_pool:  6450 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1873 \n",
      "\n",
      "\t # of sent in y_train:  1873 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7558306041830499 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  180 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 179....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 180 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6440 \n",
      "\n",
      "\t # of sent in y_pool:  6440 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1883 \n",
      "\n",
      "\t # of sent in y_train:  1883 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7554044770020106 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  181 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 180....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 181 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6430 \n",
      "\n",
      "\t # of sent in y_pool:  6430 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1893 \n",
      "\n",
      "\t # of sent in y_train:  1893 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7599322177589576 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  182 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 181....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 182 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6420 \n",
      "\n",
      "\t # of sent in y_pool:  6420 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1903 \n",
      "\n",
      "\t # of sent in y_train:  1903 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.757199874210337 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  183 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 182....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 183 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6410 \n",
      "\n",
      "\t # of sent in y_pool:  6410 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1913 \n",
      "\n",
      "\t # of sent in y_train:  1913 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7578750217815826 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  184 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 183....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 184 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6400 \n",
      "\n",
      "\t # of sent in y_pool:  6400 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1923 \n",
      "\n",
      "\t # of sent in y_train:  1923 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7602011091955515 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  185 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 184....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 185 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6390 \n",
      "\n",
      "\t # of sent in y_pool:  6390 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1933 \n",
      "\n",
      "\t # of sent in y_train:  1933 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7595735890472664 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  186 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 185....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 186 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6380 \n",
      "\n",
      "\t # of sent in y_pool:  6380 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1943 \n",
      "\n",
      "\t # of sent in y_train:  1943 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7574620589788863 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  187 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 186....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 187 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6370 \n",
      "\n",
      "\t # of sent in y_pool:  6370 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1953 \n",
      "\n",
      "\t # of sent in y_train:  1953 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7603799556189467 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  188 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 187....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 188 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6360 \n",
      "\n",
      "\t # of sent in y_pool:  6360 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1963 \n",
      "\n",
      "\t # of sent in y_train:  1963 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7567591011061094 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  189 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 188....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 189 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6350 \n",
      "\n",
      "\t # of sent in y_pool:  6350 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1973 \n",
      "\n",
      "\t # of sent in y_train:  1973 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7589680264996403 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  190 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 189....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "STARTING iteration 190 \n",
      "\n",
      "\n",
      "Task 1: storing the sentence according to max uncertainty found within words of sentence......\n",
      "\n",
      "\n",
      "Task 1 completed.....\n",
      "\n",
      "\n",
      "Task 2 Finding top 10 most uncertain sentences..... \n",
      "\n",
      "Task 2 completed.....\n",
      "\n",
      "\n",
      "Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\n",
      "\n",
      "\t # of sent in X_pool:  6340 \n",
      "\n",
      "\t # of sent in y_pool:  6340 \n",
      "\n",
      "\n",
      "\t # of sent in X_train:  1983 \n",
      "\n",
      "\t # of sent in y_train:  1983 \n",
      "\n",
      "\n",
      "Task 3 completed.....\n",
      "\n",
      "\n",
      "Task 4: training on new train dataset....\n",
      " \n",
      "Task 4 completed....\n",
      "\n",
      " \n",
      "f1 Score for testa is :  0.7653689607252366 \n",
      "\n",
      "\n",
      "len of prdict_f1_testa  191 \n",
      "\n",
      "prediction of testa completed....\n",
      "\n",
      "Task 5 completed of iteration 190....\n",
      "\n",
      "\n",
      "========================================================\n",
      "\n",
      "\n",
      "\n",
      "Experiment finished after total 190 iterations \n",
      "no of sent in training set : 1983\n",
      "Final classification report of testa and testb: \n",
      "\n",
      "\n",
      "=================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC      0.641     0.774     0.702       984\n",
      "       I-LOC      0.678     0.763     0.718       337\n",
      "      B-MISC      0.636     0.488     0.552       445\n",
      "      I-MISC      0.608     0.524     0.563       654\n",
      "       B-ORG      0.836     0.761     0.796      1700\n",
      "       I-ORG      0.826     0.778     0.801      1366\n",
      "       B-PER      0.879     0.806     0.841      1222\n",
      "       I-PER      0.875     0.916     0.895       859\n",
      "\n",
      "   micro avg      0.779     0.754     0.766      7567\n",
      "   macro avg      0.747     0.726     0.734      7567\n",
      "weighted avg      0.782     0.754     0.765      7567\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC      0.807     0.775     0.791      1084\n",
      "       I-LOC      0.725     0.615     0.666       325\n",
      "      B-MISC      0.714     0.560     0.628       339\n",
      "      I-MISC      0.698     0.594     0.642       557\n",
      "       B-ORG      0.814     0.846     0.830      1400\n",
      "       I-ORG      0.831     0.810     0.820      1104\n",
      "       B-PER      0.853     0.882     0.867       735\n",
      "       I-PER      0.905     0.950     0.927       634\n",
      "\n",
      "   micro avg      0.813     0.791     0.802      6178\n",
      "   macro avg      0.793     0.754     0.771      6178\n",
      "weighted avg      0.809     0.791     0.799      6178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iteration_num = 0\n",
    "\n",
    "while predict_f1_testa[-1] < 0.7630 or predict_f1_testb[-1] < 0.7982:\n",
    "    iteration_num +=1\n",
    "    print(\"STARTING iteration {}\".format(iteration_num), \"\\n\\n\")\n",
    "    \n",
    "    X_pool_prob = crf.predict_marginals(X_pool)   \n",
    "\n",
    "    print(\"Task 1: storing the sentence according to max uncertainty found within words of sentence......\\n\\n\")\n",
    "\n",
    "    import operator\n",
    "\n",
    "    wanted_sent_index = []\n",
    "    wanted_sent_uncertainty = []\n",
    "    sent_count = -1\n",
    "\n",
    "    for sent in X_pool_prob:\n",
    "\n",
    "        sent_count += 1\n",
    "        word_count = -1\n",
    "        meaning_ful_sent = False\n",
    "\n",
    "        temp_word_uncertainty = []\n",
    "\n",
    "        for word in sent:\n",
    "\n",
    "                word_count += 1\n",
    "                max_dict_key = max(word.items(), key=operator.itemgetter(1))[0]                    # stores class having highest probability\n",
    "\n",
    "                max_dict_prob = word[max_dict_key]                                                     # stores max prob of abv class\n",
    "                classification_uncertainty = 1 - max_dict_prob\n",
    "\n",
    "                temp_word_uncertainty.append(classification_uncertainty)\n",
    "\n",
    "          \n",
    "        if len(temp_word_uncertainty) < 2:\n",
    "            average_of_top_2_LC = 0\n",
    "        else:    \n",
    "            first_max_number = max(temp_word_uncertainty)\n",
    "            temp_word_uncertainty.remove(first_max_number)\n",
    "            second_max_number = max(temp_word_uncertainty)\n",
    "            average_of_top_2_LC = (first_max_number + second_max_number)/2                           # average of LC of two words in a sentence\n",
    "            \n",
    "        wanted_sent_uncertainty.append(average_of_top_2_LC)\n",
    "        wanted_sent_index.append(sent_count)\n",
    "\n",
    "    \n",
    "    print(\"Task 1 completed.....\\n\\n\")\n",
    "\n",
    "    print(\"Task 2 Finding top 10 most uncertain sentences..... \\n\")\n",
    "    top_ten_uncertain_index = sorted(range(len(wanted_sent_uncertainty)), key=lambda i: wanted_sent_uncertainty[i])[-10:]\n",
    "\n",
    "    print(\"Task 2 completed.....\\n\\n\")\n",
    "\n",
    "    print(\"Task 3 : Remove 10 most uncertain sent from X_pool and add them for training....\\n\")\n",
    "\n",
    "    n_labeled_examples = len(X_pool)\n",
    "\n",
    "\n",
    "    training_indices = top_ten_uncertain_index\n",
    "\n",
    "    initial_X_train.extend([X_pool[x] for x in training_indices])       #[main_list[x] for x in indexes]\n",
    "    initial_Y_train.extend([y_pool[x] for x in training_indices])\n",
    "\n",
    "    # Isolate the non-training examples we'll be querying.\n",
    "    X_pool = np.delete(X_pool, training_indices).tolist()\n",
    "    y_pool = np.delete(y_pool, training_indices).tolist()\n",
    "\n",
    "    print(\"\\t # of sent in X_pool: \", len(X_pool), \"\\n\")\n",
    "    print(\"\\t # of sent in y_pool: \", len(y_pool), \"\\n\\n\")\n",
    "\n",
    "    print(\"\\t # of sent in X_train: \", len(initial_X_train), \"\\n\")\n",
    "    print(\"\\t # of sent in y_train: \", len(initial_Y_train), \"\\n\\n\")\n",
    "\n",
    "    print(\"Task 3 completed.....\\n\\n\")\n",
    "\n",
    "    print(\"Task 4: training on new train dataset....\\n \")\n",
    "\n",
    "    crf.fit(initial_X_train, initial_Y_train)\n",
    "    print(\"Task 4 completed....\\n\\n \")\n",
    "\n",
    "    \"Task 5: print and store result.....\\n\"\n",
    "    if (predict_f1_testa[-1] < 0.7630):\n",
    "        y_preda = crf.predict(X_testa)                                   ## Iter 2\n",
    "        predict_f1_testa.append(metrics.flat_f1_score(y_testa, y_preda, average='weighted', labels=labels))      # Return F1 score for sequence items.\n",
    "        print(\"f1 Score for testa is : \", predict_f1_testa[-1], \"\\n\")\n",
    "        print(\"\\nlen of prdict_f1_testa \", len(predict_f1_testa),\"\\n\")\n",
    "    else: \n",
    "        print(\"prediction of testa completed....\\n\")\n",
    "                                                                                     # check sklearn.metrics.f1_score parameters\n",
    "    if (predict_f1_testb[-1] < 0.7982):         \n",
    "        y_predb = crf.predict(X_testb)\n",
    "        predict_f1_testb.append(metrics.flat_f1_score(y_testb, y_predb, average='weighted', labels=labels))      # Return F1 score for sequence items.\n",
    "        print(\"f1 Score for testb is : \", predict_f1_testb[-1], \"\\n\")\n",
    "        print(\"\\nlen of prdict_f1_testb \", len(predict_f1_testb),\"\\n\")\n",
    "    else: \n",
    "        print(\"prediction of testa completed....\\n\")\n",
    "\n",
    "    print(\"Task 5 completed of iteration {}....\\n\\n\\n========================================================\\n\\n\\n\".format(iteration_num))\n",
    "\n",
    "    \n",
    "print(\"Experiment finished after total {} iterations \".format(iteration_num) )\n",
    "print(\"no of sent in training set : {}\".format(len(initial_X_train)))\n",
    "\n",
    "print(\"Final classification report of testa and testb: \\n\\n\")\n",
    "print(\"=================================================\")\n",
    "# group B and I results\n",
    "sorted_labels = sorted(\n",
    "    labels, \n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_testa, y_preda, labels=sorted_labels, digits=3\n",
    "))\n",
    "\n",
    "# group B and I results\n",
    "sorted_labels = sorted(\n",
    "    labels, \n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_testb, y_predb, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191\n",
      "191\n",
      "163\n",
      "163\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('0_AL_SpanishConLL2002_top2LC_graph_data_testa_f1_pred.pkl', 'wb') as f:\n",
    "    pickle.dump(predict_f1_testa, f)\n",
    "    \n",
    "with open('0_AL_SpanishConLL2002_top2LC_graph_data_testb_f1_pred.pkl', 'wb') as f:\n",
    "    pickle.dump(predict_f1_testb, f)    \n",
    "    \n",
    "with open('0_AL_SpanishConLL2002_top2LC_graph_data_testa_f1_pred.pkl', 'rb') as f:\n",
    "    mynewlist_a = pickle.load(f)\n",
    "    \n",
    "with open('0_AL_SpanishConLL2002_top2LC_graph_data_testb_f1_pred.pkl', 'rb') as f:\n",
    "    mynewlist_b = pickle.load(f)    \n",
    "    \n",
    "print(len(mynewlist_a))\n",
    "print(len(predict_f1_testa))\n",
    "print(len(mynewlist_b))\n",
    "print(len(predict_f1_testb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1983\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "Xa = [83+item*10 for item in range(191)]\n",
    "print(Xa[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1703\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "Xa = [83+item*10 for item in range(163)]\n",
    "print(Xa[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
